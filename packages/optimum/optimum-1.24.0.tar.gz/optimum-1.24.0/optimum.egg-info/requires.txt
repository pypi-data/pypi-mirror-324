transformers>=4.29
torch>=1.11
packaging
numpy
huggingface_hub>=0.8.0

[amd]
optimum-amd

[benchmark]
optuna
tqdm
scikit-learn
seqeval
torchvision
evaluate>=0.2.0

[dev]
accelerate
pytest<=8.0.0
requests
parameterized
pytest-xdist
Pillow
sacremoses
torchvision
torchaudio
einops
timm
scikit-learn
sentencepiece
rjieba
black~=23.1
ruff==0.1.5

[diffusers]
diffusers

[doc-build]
accelerate

[exporters]
onnx
onnxruntime
timm
transformers<4.49.0,>=4.36

[exporters-gpu]
onnx
onnxruntime-gpu
timm
transformers<4.49.0,>=4.36

[exporters-tf]
tensorflow<=2.12.1,>=2.4
tf2onnx
onnx
onnxruntime
timm
h5py
numpy<1.24.0
datasets<=2.16
transformers<4.38,>=4.36

[furiosa]
optimum-furiosa

[graphcore]
optimum-graphcore

[habana]
optimum-habana
transformers<4.46.0,>=4.45.0

[intel]
optimum-intel>=1.18.0

[ipex]
optimum-intel[ipex]>=1.18.0

[neural-compressor]
optimum-intel[neural-compressor]>=1.18.0

[neuron]
optimum-neuron[neuron]>=0.0.20
transformers<4.42.0,>=4.36.2

[neuronx]
optimum-neuron[neuronx]>=0.0.20
transformers<4.42.0,>=4.36.2

[nncf]
optimum-intel[nncf]>=1.18.0

[onnxruntime]
onnx
onnxruntime>=1.11.0
datasets>=1.2.1
evaluate
protobuf>=3.20.1
transformers<4.49.0,>=4.36

[onnxruntime-gpu]
onnx
onnxruntime-gpu>=1.11.0
datasets>=1.2.1
evaluate
protobuf>=3.20.1
transformers<4.49.0,>=4.36

[onnxruntime-training]
torch-ort
onnxruntime-training>=1.11.0
datasets>=1.2.1
accelerate
evaluate
protobuf>=3.20.1
transformers<4.49.0,>=4.36

[openvino]
optimum-intel[openvino]>=1.18.0

[quality]
black~=23.1
ruff==0.1.5

[quanto]
optimum-quanto>=0.2.4

[tests]
accelerate
pytest<=8.0.0
requests
parameterized
pytest-xdist
Pillow
sacremoses
torchvision
torchaudio
einops
timm
scikit-learn
sentencepiece
rjieba
