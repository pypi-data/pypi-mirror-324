Metadata-Version: 2.4
Name: agentic-fleet
Version: 0.4.72
Summary: A powerful multi-agent system for adaptive AI reasoning and automation
Project-URL: Homepage, https://github.com/qredence/agenticfleet
Project-URL: Documentation, https://github.com/qredence/agenticfleet/tree/main/docs
Project-URL: Repository, https://github.com/qredence/agenticfleet.git
Project-URL: Issues, https://github.com/qredence/agenticfleet/issues
Project-URL: Source, https://github.com/qredence/agenticfleet
Project-URL: Docker, https://hub.docker.com/r/qredenceai/agenticfleet
Author-email: Zachary BENSALEM <contact@qredence.ai>
License: Apache-2.0
License-File: LICENSE
Keywords: AI,adaptive,agents,ai,autogen,autogen-sample,automation,magentic-one,multi-agent,reasoning
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: Implementation :: CPython
Requires-Python: >=3.10
Requires-Dist: aioconsole>=0.8.1
Requires-Dist: aiofiles>=23.1.0
Requires-Dist: aiohttp<4.0.0,>=3.11.11
Requires-Dist: asyncio>=3.4.3
Requires-Dist: authlib>=1.4.0
Requires-Dist: autogen-agentchat<0.5.0,>=0.4.5
Requires-Dist: autogen-core<0.5.0,>=0.4.5
Requires-Dist: autogen-ext[azure,openai]<0.5.0,>=0.4.5
Requires-Dist: autogen-ext[diskcache]<0.5.0,>=0.4.5
Requires-Dist: autogen-ext[docker]<0.5.0,>=0.4.5
Requires-Dist: autogen-ext[langchain]<0.5.0,>=0.4.5
Requires-Dist: autogen-ext[magentic-one]<0.5.0,>=0.4.5
Requires-Dist: autogen-ext[web-surfer]<0.5.0,>=0.4.5
Requires-Dist: axios>=0.4.0
Requires-Dist: azure-ai-inference>=1.0.0b6
Requires-Dist: azure-ai-ml>=1.12.1
Requires-Dist: azure-ai-projects>=1.0.0b4
Requires-Dist: azure-core>=1.32.0
Requires-Dist: azure-cosmos>=4.9.0
Requires-Dist: azure-identity>=1.19.0
Requires-Dist: azure-keyvault-secrets>=4.9.0
Requires-Dist: azure-search-documents==11.6.0b4
Requires-Dist: azure-storage-blob>=12.24.0
Requires-Dist: beautifulsoup4>=4.12.0
Requires-Dist: bing>=0.31
Requires-Dist: black>=24.10.0
Requires-Dist: chainlit>=2.1.0
Requires-Dist: codecov>=2.1.13
Requires-Dist: composio-core>=0.6.11.post1
Requires-Dist: deepseek>=0.1.0
Requires-Dist: docker>=7.1.0
Requires-Dist: fastapi>=0.109.0
Requires-Dist: gunicorn>=23.0.0
Requires-Dist: httpx>=0.25.0
Requires-Dist: ipykernel>=6.29.5
Requires-Dist: jsonlines>=4.0.0
Requires-Dist: magentic-one-cli>=0.2.2
Requires-Dist: markitdown>=0.0.1a3
Requires-Dist: matplotlib>=3.10.0
Requires-Dist: numpy<2.0,>=1.26
Requires-Dist: ollama>=0.1.5
Requires-Dist: opentelemetry-instrumentation-fastapi>=0.44b0
Requires-Dist: packaging>=23.2
Requires-Dist: pandas>=2.2.3
Requires-Dist: pillow>=11.0.0
Requires-Dist: playwright
Requires-Dist: plotly-express>=0.4.1
Requires-Dist: plotly>=5.16.0
Requires-Dist: psutil>=5.9.6
Requires-Dist: psycopg2-binary>=2.9.9
Requires-Dist: puremagic>=1.28
Requires-Dist: pydantic-settings>=2.2.1
Requires-Dist: pydantic>=2.5.2
Requires-Dist: pytest-asyncio>=0.25.2
Requires-Dist: pytest-cov>=6.0.0
Requires-Dist: pytest>=8.3.4
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: python-multipart>=0.0.6
Requires-Dist: pytz>=2024.2
Requires-Dist: redis>=5.2.1
Requires-Dist: requests-html>=0.10.0
Requires-Dist: requests>=2.32.3
Requires-Dist: rich>=13.9.4
Requires-Dist: ruff==0.4.8
Requires-Dist: scikit-learn>=1.6.1
Requires-Dist: seaborn>=0.13.0
Requires-Dist: semantic-kernel>=1.19.0
Requires-Dist: sqlalchemy[asyncio]>=2.0.28
Requires-Dist: starlette>=0.41.3
Requires-Dist: supabase>=2.3.1
Requires-Dist: tenacity>=9.0.0
Requires-Dist: tiktoken>=0.8.0
Requires-Dist: typer>=0.15.1
Requires-Dist: typing-extensions>=4.8.0
Requires-Dist: uvicorn>=0.24.0
Requires-Dist: yfinance>=0.2.51
Provides-Extra: dev
Requires-Dist: black>=23.11.0; extra == 'dev'
Requires-Dist: pre-commit>=3.5.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.1; extra == 'dev'
Requires-Dist: pytest-cov>=4.1.0; extra == 'dev'
Requires-Dist: pytest>=7.4.3; extra == 'dev'
Requires-Dist: ruff>=0.1.0; extra == 'dev'
Requires-Dist: tox>=4.11.3; extra == 'dev'
Provides-Extra: docs
Requires-Dist: myst-parser>=2.0.0; extra == 'docs'
Requires-Dist: sphinx-autodoc-typehints>=1.25.2; extra == 'docs'
Requires-Dist: sphinx-copybutton>=0.5.2; extra == 'docs'
Requires-Dist: sphinx-rtd-theme>=2.0.0; extra == 'docs'
Requires-Dist: sphinx>=7.2.6; extra == 'docs'
Provides-Extra: grpc
Requires-Dist: grpcio-tools>=1.62.0; extra == 'grpc'
Requires-Dist: protobuf>=5.29.3; extra == 'grpc'
Provides-Extra: models
Requires-Dist: deepseek>=0.1.0; extra == 'models'
Requires-Dist: google-cloud-aiplatform>=1.38.0; extra == 'models'
Requires-Dist: google-generativeai>=0.3.0; extra == 'models'
Requires-Dist: ollama>=0.1.5; extra == 'models'
Provides-Extra: test
Requires-Dist: coverage>=7.4.0; extra == 'test'
Requires-Dist: pytest-asyncio>=0.21.1; extra == 'test'
Requires-Dist: pytest-cov>=4.1.0; extra == 'test'
Requires-Dist: pytest-mock>=3.12.0; extra == 'test'
Requires-Dist: pytest-timeout>=2.2.0; extra == 'test'
Requires-Dist: pytest-xdist>=3.5.0; extra == 'test'
Requires-Dist: pytest>=7.4.3; extra == 'test'
Description-Content-Type: text/markdown

# AgenticFleet

A powerful multi-agent system for adaptive AI reasoning and automation. AgenticFleet combines Chainlit's interactive interface with AutoGen's multi-agent capabilities to create a flexible, powerful AI assistant platform.

![Pepy Total Downloads](https://img.shields.io/pepy/dt/agentic-fleet?style=for-the-badge&color=blue)

![GitHub License](https://img.shields.io/github/license/qredence/agenticfleet)
![GitHub forks](https://img.shields.io/github/forks/qredence/agenticfleet)
![GitHub Repo stars](https://img.shields.io/github/stars/qredence/agenticfleet)

[![Codacy Badge](https://app.codacy.com/project/badge/Grade/cf5bcfbdbf50493b9b5de381c24dc147)](https://app.codacy.com/gh/Qredence/AgenticFleet/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)

![chainlitlight](https://github.com/user-attachments/assets/0d070c34-e5a8-40be-94f5-5c8307f1f64c)

## Quick Start with Docker

```bash
# Pull the latest image
docker pull qredence/agenticfleet:latest

# Run with minimum required configuration
docker run -d -p 8001:8001 qredence/agenticfleet:latest

# Or run with additional configuration
docker run -d -p 8001:8001 \
  -e AZURE_OPENAI_API_KEY=your_key \
  -e AZURE_OPENAI_ENDPOINT=your_endpoint \
  -e AZURE_OPENAI_DEPLOYMENT=your_deployment \
  -e AZURE_OPENAI_MODEL=your_model \
  -e USE_OAUTH=true \
  -e OAUTH_GITHUB_CLIENT_ID=your_client_id \
  -e OAUTH_GITHUB_CLIENT_SECRET=your_client_secret \
  qredence/agenticfleet:latest

# Run without OAuth
docker run -d -p 8001:8001 \
  -e AZURE_OPENAI_API_KEY=your_key \
  -e AZURE_OPENAI_ENDPOINT=your_endpoint \
  -e USE_OAUTH=false \
  qredence/agenticfleet:latest
```

## Core Components

AgenticFleet operates through a coordinated team of specialized agents:

- **WebSurfer**: Expert web navigation agent
  - Extracts information from web pages
  - Captures and processes screenshots
  - Provides structured summaries of findings

- **FileSurfer**: File system specialist
  - Searches and analyzes workspace files
  - Manages file operations efficiently
  - Extracts relevant information from documents

- **Coder**: Development expert
  - Generates and reviews code
  - Implements solutions
  - Maintains code quality

- **Executor**: Code execution specialist
  - Safely runs code in isolated workspace
  - Monitors execution and handles timeouts
  - Provides detailed execution feedback

## Model Provider Installation

Install providers using pip:

```bash
# Install base package
pip install agentic-fleet

# Install all model providers
pip install "agentic-fleet[models]"

# Or install individual providers
pip install "google-cloud-aiplatform>=1.38.0" "google-generativeai>=0.3.0"  # For Gemini
pip install "deepseek>=0.1.0"  # For DeepSeek
pip install "ollama>=0.1.5"  # For Ollama
```

## Model Provider Usage

```python
from agentic_fleet.models import ModelFactory, ModelProvider
from autogen_core.models import UserMessage

# Create Azure OpenAI client
azure_client = ModelFactory.create(
    ModelProvider.AZURE_OPENAI,
    deployment="your-deployment",
    model="gpt-4",
    endpoint="your-endpoint"
)

# Create Gemini client
gemini_client = ModelFactory.create(
    ModelProvider.GEMINI,
    api_key="your-api-key"
)

# Create CogCache client
cogcache_client = ModelFactory.create(
    ModelProvider.COGCACHE,
    api_key="your-cogcache-key",
    model="gpt-4"
)

# Create local Ollama client
ollama_client = ModelFactory.create(
    ModelProvider.OLLAMA,
    model="llama2:latest"
)

# Use any client
async def test_model(client):
    response = await client.create([
        UserMessage(content="What is the capital of France?", source="user")
    ])
    print(response)
```

## Key Features

- **Advanced Capabilities**
  - Multiple LLM provider support
  - GitHub OAuth authentication
  - Configurable agent behaviors
  - Comprehensive error handling and recovery
  - Multi-modal content processing (text, images)
  - Execution workspace isolation
  
- **Developer-Friendly**
  - Easy-to-use CLI
  - Extensive documentation
  - Flexible configuration
  - Active community support

## Installation Options

### Option 1: Direct Installation

1. Install using uv (recommended):

```bash
uv pip install agentic-fleet
playwright install --with-deps chromium  # Optional: Install Playwright
```

2. Configure environment:

```bash
cp .env.example .env
# Edit .env with your API keys
```

3. Start the server:

```bash
agenticfleet start        # With OAuth
agenticfleet start no-oauth  # Without OAuth
```

### Option 2: Docker Setup

1. Clone and configure:

```bash
git clone https://github.com/qredence/agenticfleet.git
cd agenticfleet
cp .env.example .env     # Configure your .env file
```

2. Build and run with Docker Compose:

```bash
# Build the image
docker compose build

# Run with OAuth enabled (default)
docker compose up

# Or run without OAuth
docker compose run -e RUN_MODE=no-oauth agenticfleet
```

### Docker Environment Configuration

You can provide environment variables in several ways:

1. Using a .env file:

```bash
cp .env.example .env
# Edit .env with your values
docker compose up
```

2. Using command line arguments:

```bash
docker compose build \
  --build-arg AZURE_OPENAI_API_KEY=your_key \
  --build-arg AZURE_OPENAI_ENDPOINT=your_endpoint \
  --build-arg USE_OAUTH=true
```

3. Using environment variables:

```bash
export AZURE_OPENAI_API_KEY=your_key
export AZURE_OPENAI_ENDPOINT=your_endpoint
docker compose up
```

4. For production deployments:

```bash
docker run -d \
  -e AZURE_OPENAI_API_KEY=your_key \
  -e AZURE_OPENAI_ENDPOINT=your_endpoint \
  -e USE_OAUTH=true \
  -p 8001:8001 \
  qredence/agenticfleet:latest
```

Key features of the Docker setup:

- Python 3.12 environment
- Automatic dependency installation
- Volume mounting for live development
- Environment variable management
- Health checking and automatic restarts
- Resource limits and optimization

### Option 3: Development Container

For VS Code users with the Dev Containers extension:

1. Open in VS Code:

```bash
code agenticfleet
```

2. Press F1 and select "Dev Containers: Open Folder in Container"

The dev container provides:

- Full Python 3.12 development environment
- Pre-configured VS Code extensions
- Integrated debugging
- Live reload capability
- All dependencies pre-installed

## Supported Model Providers

AgenticFleet supports multiple LLM providers through a unified interface:

- **OpenAI**
  - GPT-4 and other OpenAI models
  - Function calling and vision capabilities
  - JSON mode support

- **Azure OpenAI**
  - Azure-hosted OpenAI models
  - Azure AD authentication support
  - Enterprise-grade security

- **Google Gemini**
  - Gemini Pro and Ultra models
  - OpenAI-compatible API
  - Multimodal capabilities

- **DeepSeek**
  - DeepSeek's language models
  - OpenAI-compatible API
  - Specialized model capabilities

- **Ollama**
  - Local model deployment
  - Various open-source models
  - Offline capabilities

- **Azure AI Foundry**
  - Azure-hosted models (e.g., Phi-4)
  - GitHub authentication
  - Enterprise integration

- **CogCache**
  - OpenAI-compatible API with caching
  - Improved response times
  - Cost optimization
  - Automatic retry handling

## System Architecture

```mermaid
graph TD
    User[Chainlit UI] -->|HTTP| App[app.py]
    App --> AgentTeam[MagenticOneGroupChat]
    AgentTeam --> WebSurfer
    AgentTeam --> FileSurfer
    AgentTeam --> Coder
    AgentTeam --> Executor
    WebSurfer -->|Selenium| Web[External Websites]
    FileSurfer -->|OS| FileSystem[Local Files]
    Executor -->|Subprocess| Code[Python/Runtime]
```

## Configuration

The `.env.example` file contains all required and recommended settings:

```env
# Required: Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_DEPLOYMENT=your_deployment
AZURE_OPENAI_MODEL=your_model

# Optional: OAuth Configuration
USE_OAUTH=false # Set to true to enable GitHub OAuth
OAUTH_GITHUB_CLIENT_ID=
OAUTH_GITHUB_CLIENT_SECRET=
OAUTH_REDIRECT_URI=http://localhost:8001/oauth/callback

# Optional: Other Model Provider Configurations
GEMINI_API_KEY=your_gemini_key
DEEPSEEK_API_KEY=your_deepseek_key
GITHUB_TOKEN=your_github_pat  # For Azure AI Foundry
COGCACHE_API_KEY=your_cogcache_key  # For CogCache proxy API
```

## Error Handling

AgenticFleet implements comprehensive error handling:

- Graceful degradation on service failures
- Detailed error logging and reporting
- Automatic cleanup of resources
- Session state recovery
- Execution timeout management

## Development

### Prerequisites

- Python 3.10-3.12 (Python 3.13 is not yet supported)
- uv package manager (recommended)
- Azure OpenAI API access

### Setup

1. Clone and install:

```bash
git clone https://github.com/qredence/agenticfleet.git
cd agenticfleet
pip install uv
uv pip install -e .
uv pip install -e ".[dev]"
```

2. Run tests:

```bash
pytest tests/
```

## Documentation

- [Installation Guide](docs/installation.md) - Detailed setup instructions
- [Usage Guide](docs/usage-guide.md) - How to use AgenticFleet
- [API Reference](docs/api-reference.md) - Complete API documentation
- [Architecture Overview](docs/agentic-fleet.md) - System architecture and design

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## Security

For security concerns, please review our [Security Policy](SECURITY.md).

## License

This project is licensed under the Apache-2.0 License - see the [LICENSE](LICENSE) file for details.

## Support

- [Issue Tracker](https://github.com/qredence/agenticfleet/issues)
- [Discussions](https://github.com/qredence/agenticfleet/discussions)
- Email: <contact@qredence.ai>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Qredence/AgenticFleet&type=Date)](https://star-history.com/#Qredence/AgenticFleet&Date)
