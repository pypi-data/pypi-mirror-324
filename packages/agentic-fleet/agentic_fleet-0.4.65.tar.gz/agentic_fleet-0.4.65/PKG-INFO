Metadata-Version: 2.4
Name: agentic-fleet
Version: 0.4.65
Summary: A powerful multi-agent system for adaptive AI reasoning and automation
Project-URL: Homepage, https://github.com/qredence/agenticfleet
Project-URL: Documentation, https://github.com/qredence/agenticfleet/tree/main/docs
Project-URL: Repository, https://github.com/qredence/agenticfleet.git
Project-URL: Issues, https://github.com/qredence/agenticfleet/issues
Project-URL: Source, https://github.com/qredence/agenticfleet
Author-email: Zachary BENSALEM <contact@qredence.ai>
License: Apache-2.0
License-File: LICENSE
Keywords: AI,adaptive,agents,ai,autogen,autogen-sample,automation,magentic-one,multi-agent,reasoning
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: Implementation :: CPython
Requires-Python: >=3.10
Requires-Dist: agentops>=0.3.21
Requires-Dist: aioconsole>=0.8.1
Requires-Dist: aiofiles>=23.1.0
Requires-Dist: aiohttp<4.0.0,>=3.11.11
Requires-Dist: asyncio>=3.4.3
Requires-Dist: authlib>=1.4.0
Requires-Dist: autogen-agentchat<0.5.0,>=0.4.4
Requires-Dist: autogen-core<0.5.0,>=0.4.4
Requires-Dist: autogen-ext[azure,openai]<0.5.0,>=0.4.4
Requires-Dist: autogen-ext[docker]<0.5.0,>=0.4.4
Requires-Dist: autogen-ext[langchain]<0.5.0,>=0.4.4
Requires-Dist: autogen-ext[magentic-one]<0.5.0,>=0.4.4
Requires-Dist: autogen-ext[web-surfer]<0.5.0,>=0.4.4
Requires-Dist: axios>=0.4.0
Requires-Dist: azure-ai-inference>=1.0.0b6
Requires-Dist: azure-ai-ml>=1.12.1
Requires-Dist: azure-ai-projects>=1.0.0b4
Requires-Dist: azure-core>=1.32.0
Requires-Dist: azure-cosmos>=4.9.0
Requires-Dist: azure-identity>=1.19.0
Requires-Dist: azure-keyvault-secrets>=4.9.0
Requires-Dist: azure-search-documents==11.6.0b4
Requires-Dist: azure-storage-blob>=12.24.0
Requires-Dist: beautifulsoup4>=4.12.0
Requires-Dist: bing>=0.31
Requires-Dist: black>=24.10.0
Requires-Dist: chainlit>=2.1.0
Requires-Dist: codecov>=2.1.13
Requires-Dist: composio-core>=0.6.11.post1
Requires-Dist: deepseek>=0.1.0
Requires-Dist: docker>=7.1.0
Requires-Dist: fastapi>=0.109.0
Requires-Dist: google-cloud-aiplatform>=1.38.0
Requires-Dist: google-generativeai>=0.3.0
Requires-Dist: grpcio-tools~=1.62.0
Requires-Dist: gunicorn>=23.0.0
Requires-Dist: httpx>=0.25.0
Requires-Dist: ipykernel>=6.29.5
Requires-Dist: jsonlines>=4.0.0
Requires-Dist: magentic-one-cli>=0.2.2
Requires-Dist: markitdown>=0.0.1a3
Requires-Dist: matplotlib>=3.10.0
Requires-Dist: numpy<2.0,>=1.26
Requires-Dist: ollama>=0.1.5
Requires-Dist: opentelemetry-instrumentation-fastapi>=0.44b0
Requires-Dist: packaging>=23.2
Requires-Dist: pandas>=2.2.3
Requires-Dist: pillow>=11.0.0
Requires-Dist: playwright<2.0.0,>=1.49.1
Requires-Dist: plotly-express>=0.4.1
Requires-Dist: plotly>=5.16.0
Requires-Dist: psutil>=5.9.6
Requires-Dist: puremagic>=1.28
Requires-Dist: pydantic-settings>=2.2.1
Requires-Dist: pydantic>=2.5.2
Requires-Dist: pytest-asyncio>=0.25.2
Requires-Dist: pytest-cov>=6.0.0
Requires-Dist: pytest>=8.3.4
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: python-multipart>=0.0.6
Requires-Dist: pytz>=2024.2
Requires-Dist: redis>=5.2.1
Requires-Dist: requests-html>=0.10.0
Requires-Dist: requests>=2.32.3
Requires-Dist: rich>=13.9.4
Requires-Dist: ruff==0.4.8
Requires-Dist: scikit-learn>=1.6.1
Requires-Dist: seaborn>=0.13.0
Requires-Dist: semantic-kernel>=1.19.0
Requires-Dist: starlette>=0.41.3
Requires-Dist: tenacity>=9.0.0
Requires-Dist: tiktoken>=0.8.0
Requires-Dist: typer>=0.15.1
Requires-Dist: typing-extensions>=4.8.0
Requires-Dist: uvicorn>=0.24.0
Requires-Dist: yfinance>=0.2.51
Provides-Extra: dev
Requires-Dist: black>=23.11.0; extra == 'dev'
Requires-Dist: pre-commit>=3.5.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.1; extra == 'dev'
Requires-Dist: pytest-cov>=4.1.0; extra == 'dev'
Requires-Dist: pytest>=7.4.3; extra == 'dev'
Requires-Dist: ruff>=0.1.0; extra == 'dev'
Requires-Dist: tox>=4.11.3; extra == 'dev'
Provides-Extra: docs
Requires-Dist: myst-parser>=2.0.0; extra == 'docs'
Requires-Dist: sphinx-autodoc-typehints>=1.25.2; extra == 'docs'
Requires-Dist: sphinx-copybutton>=0.5.2; extra == 'docs'
Requires-Dist: sphinx-rtd-theme>=2.0.0; extra == 'docs'
Requires-Dist: sphinx>=7.2.6; extra == 'docs'
Provides-Extra: models
Requires-Dist: deepseek>=0.1.0; extra == 'models'
Requires-Dist: google-cloud-aiplatform>=1.38.0; extra == 'models'
Requires-Dist: google-generativeai>=0.3.0; extra == 'models'
Requires-Dist: ollama>=0.1.5; extra == 'models'
Provides-Extra: test
Requires-Dist: coverage>=7.4.0; extra == 'test'
Requires-Dist: pytest-asyncio>=0.21.1; extra == 'test'
Requires-Dist: pytest-cov>=4.1.0; extra == 'test'
Requires-Dist: pytest-mock>=3.12.0; extra == 'test'
Requires-Dist: pytest-timeout>=2.2.0; extra == 'test'
Requires-Dist: pytest-xdist>=3.5.0; extra == 'test'
Requires-Dist: pytest>=7.4.3; extra == 'test'
Description-Content-Type: text/markdown

# AgenticFleet

A powerful multi-agent system for adaptive AI reasoning and automation. AgenticFleet combines Chainlit's interactive interface with AutoGen's multi-agent capabilities to create a flexible, powerful AI assistant platform.

![Pepy Total Downloads](https://img.shields.io/pepy/dt/agentic-fleet?style=for-the-badge&color=blue)

![GitHub License](https://img.shields.io/github/license/qredence/agenticfleet)
![GitHub forks](https://img.shields.io/github/forks/qredence/agenticfleet)
![GitHub Repo stars](https://img.shields.io/github/stars/qredence/agenticfleet)

[![Codacy Badge](https://app.codacy.com/project/badge/Grade/cf5bcfbdbf50493b9b5de381c24dc147)](https://app.codacy.com/gh/Qredence/AgenticFleet/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)

![chainlitlight](https://github.com/user-attachments/assets/0d070c34-e5a8-40be-94f5-5c8307f1f64c)

## Core Components

AgenticFleet operates through a coordinated team of specialized agents:

- **WebSurfer**: Expert web navigation agent
  - Extracts information from web pages
  - Captures and processes screenshots
  - Provides structured summaries of findings

- **FileSurfer**: File system specialist
  - Searches and analyzes workspace files
  - Manages file operations efficiently
  - Extracts relevant information from documents

- **Coder**: Development expert
  - Generates and reviews code
  - Implements solutions
  - Maintains code quality

- **Executor**: Code execution specialist
  - Safely runs code in isolated workspace
  - Monitors execution and handles timeouts
  - Provides detailed execution feedback

## Supported Model Providers

AgenticFleet supports multiple LLM providers through a unified interface:

- **OpenAI**
  - GPT-4 and other OpenAI models
  - Function calling and vision capabilities
  - JSON mode support

- **Azure OpenAI**
  - Azure-hosted OpenAI models
  - Azure AD authentication support
  - Enterprise-grade security

- **Google Gemini**
  - Gemini Pro and Ultra models
  - OpenAI-compatible API
  - Multimodal capabilities

- **DeepSeek**
  - DeepSeek's language models
  - OpenAI-compatible API
  - Specialized model capabilities

- **Ollama**
  - Local model deployment
  - Various open-source models
  - Offline capabilities

- **Azure AI Foundry**
  - Azure-hosted models (e.g., Phi-4)
  - GitHub authentication
  - Enterprise integration

- **CogCache**
  - OpenAI-compatible API with caching
  - Improved response times
  - Cost optimization
  - Automatic retry handling

### Model Provider Installation

Install providers using pip:

```bash
# Install base package
pip install agentic-fleet

# Install all model providers
pip install "agentic-fleet[models]"

# Or install individual providers
pip install "google-cloud-aiplatform>=1.38.0" "google-generativeai>=0.3.0"  # For Gemini
pip install "deepseek>=0.1.0"  # For DeepSeek
pip install "ollama>=0.1.5"  # For Ollama
```

### Model Provider Usage

```python
from agentic_fleet.models import ModelFactory, ModelProvider
from autogen_core.models import UserMessage

# Create Azure OpenAI client
azure_client = ModelFactory.create(
    ModelProvider.AZURE_OPENAI,
    deployment="your-deployment",
    model="gpt-4",
    endpoint="your-endpoint"
)

# Create Gemini client
gemini_client = ModelFactory.create(
    ModelProvider.GEMINI,
    api_key="your-api-key"
)

# Create CogCache client
cogcache_client = ModelFactory.create(
    ModelProvider.COGCACHE,
    api_key="your-cogcache-key",
    model="gpt-4"
)

# Create local Ollama client
ollama_client = ModelFactory.create(
    ModelProvider.OLLAMA,
    model="llama2:latest"
)

# Use any client
async def test_model(client):
    response = await client.create([
        UserMessage(content="What is the capital of France?", source="user")
    ])
    print(response)
```

## Key Features

- **Multi-Agent System**
  - Coordinated team of specialized AI agents
  - Real-time inter-agent communication
  - Task planning and execution tracking
  
- **Interactive Interface**
  - Real-time streaming responses
  - Code syntax highlighting
  - Markdown rendering
  - File upload/download support
  - Progress visualization with task lists

- **Advanced Capabilities**
  - Multiple LLM provider support
  - GitHub OAuth authentication
  - Configurable agent behaviors
  - Comprehensive error handling and recovery
  - Multi-modal content processing (text, images)
  - Execution workspace isolation
  
- **Developer-Friendly**
  - Easy-to-use CLI
  - Extensive documentation
  - Flexible configuration
  - Active community support

## Quick Start

1. Install AgenticFleet using uv (recommended):

```bash
uv pip install agentic-fleet
```

```bash
playwright install --with-deps chromium # Optional: Install Playwright Chromium dependencies
```

2. Copy and configure environment variables:

```bash
# Copy the example environment file
cp .env.example .env

# Open .env and update with your values
# Required: Add your Azure OpenAI credentials
# Optional: Configure OAuth settings
```

3. Start the server:

```bash
agenticfleet start   # Enable GitHub authentication
agenticfleet start --no-oauth # Default local mode
```

The web interface will be available at `http://localhost:8001`.

## System Architecture

```mermaid
graph TD
    User[Chainlit UI] -->|HTTP| App[app.py]
    App --> AgentTeam[MagenticOneGroupChat]
    AgentTeam --> WebSurfer
    AgentTeam --> FileSurfer
    AgentTeam --> Coder
    AgentTeam --> Executor
    WebSurfer -->|Selenium| Web[External Websites]
    FileSurfer -->|OS| FileSystem[Local Files]
    Executor -->|Subprocess| Code[Python/Runtime]
```

## Configuration

The `.env.example` file contains all required and recommended settings:

```env
# Required: Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_DEPLOYMENT=your_deployment
AZURE_OPENAI_MODEL=your_model

# Optional: OAuth Configuration
USE_OAUTH=false # Set to true to enable GitHub OAuth
OAUTH_GITHUB_CLIENT_ID=
OAUTH_GITHUB_CLIENT_SECRET=
OAUTH_REDIRECT_URI=http://localhost:8001/oauth/callback

# Optional: Other Model Provider Configurations
GEMINI_API_KEY=your_gemini_key
DEEPSEEK_API_KEY=your_deepseek_key
GITHUB_TOKEN=your_github_pat  # For Azure AI Foundry
COGCACHE_API_KEY=your_cogcache_key  # For CogCache proxy API
```

## Error Handling

AgenticFleet implements comprehensive error handling:

- Graceful degradation on service failures
- Detailed error logging and reporting
- Automatic cleanup of resources
- Session state recovery
- Execution timeout management

## Development

### Prerequisites

- Python 3.10-3.12 (Python 3.13 is not yet supported)
- uv package manager (recommended)
- Azure OpenAI API access

### Setup

  1. Clone and install:

```bash
git clone https://github.com/qredence/agenticfleet.git
cd agenticfleet
pip install uv
uv pip install -e .
uv pip install -e ".[dev]"
```

2. Run tests:

```bash
pytest tests/
```

## Documentation

- [Installation Guide](docs/installation.md) - Detailed setup instructions
- [Usage Guide](docs/usage-guide.md) - How to use AgenticFleet
- [API Reference](docs/api-reference.md) - Complete API documentation
- [Architecture Overview](docs/agentic-fleet.md) - System architecture and design

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## Security

For security concerns, please review our [Security Policy](SECURITY.md).

## License

This project is licensed under the Apache-2.0 License - see the [LICENSE](LICENSE) file for details.

## Support

- [Issue Tracker](https://github.com/qredence/agenticfleet/issues)
- [Discussions](https://github.com/qredence/agenticfleet/discussions)
- Email: <contact@qredence.ai>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Qredence/AgenticFleet&type=Date)](https://star-history.com/#Qredence/AgenticFleet&Date)
