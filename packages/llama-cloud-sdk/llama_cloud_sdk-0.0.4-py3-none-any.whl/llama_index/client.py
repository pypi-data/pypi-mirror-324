# This file was auto-generated by Fern from our API Definition.

import typing
from .environment import LlamaCloudEnvironment
import httpx
from .core.client_wrapper import SyncClientWrapper
from .data_sinks.client import DataSinksClient
from .data_sources.client import DataSourcesClient
from .embedding_model_configs.client import EmbeddingModelConfigsClient
from .organizations.client import OrganizationsClient
from .projects.client import ProjectsClient
from .files.client import FilesClient
from .pipelines.client import PipelinesClient
from .retrievers.client import RetrieversClient
from .jobs.client import JobsClient
from .evals.client import EvalsClient
from .parsing.client import ParsingClient
from .component_definitions.client import ComponentDefinitionsClient
from .chat_apps.client import ChatAppsClient
from .llama_extract.client import LlamaExtractClient
from .reports.client import ReportsClient
from .core.client_wrapper import AsyncClientWrapper
from .data_sinks.client import AsyncDataSinksClient
from .data_sources.client import AsyncDataSourcesClient
from .embedding_model_configs.client import AsyncEmbeddingModelConfigsClient
from .organizations.client import AsyncOrganizationsClient
from .projects.client import AsyncProjectsClient
from .files.client import AsyncFilesClient
from .pipelines.client import AsyncPipelinesClient
from .retrievers.client import AsyncRetrieversClient
from .jobs.client import AsyncJobsClient
from .evals.client import AsyncEvalsClient
from .parsing.client import AsyncParsingClient
from .component_definitions.client import AsyncComponentDefinitionsClient
from .chat_apps.client import AsyncChatAppsClient
from .llama_extract.client import AsyncLlamaExtractClient
from .reports.client import AsyncReportsClient


class LlamaCloud:
    """
    Use this class to access the different functions within the SDK. You can instantiate any number of clients with different configuration that will propagate to these functions.

    Parameters
    ----------
    base_url : typing.Optional[str]
        The base url to use for requests from the client.

    environment : LlamaCloudEnvironment
        The environment to use for requests from the client. from .environment import LlamaCloudEnvironment



        Defaults to LlamaCloudEnvironment.DEFAULT



    token : typing.Optional[typing.Union[str, typing.Callable[[], str]]]
    timeout : typing.Optional[float]
        The timeout to be used, in seconds, for requests. By default the timeout is 60 seconds, unless a custom httpx client is used, in which case this default is not enforced.

    follow_redirects : typing.Optional[bool]
        Whether the default httpx client follows redirects or not, this is irrelevant if a custom httpx client is passed in.

    httpx_client : typing.Optional[httpx.Client]
        The httpx client to use for making requests, a preconfigured client is used by default, however this is useful should you want to pass in any custom httpx configuration.

    Examples
    --------
    from llama_index import LlamaCloud

    client = LlamaCloud(
        token="YOUR_TOKEN",
    )
    """

    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: LlamaCloudEnvironment = LlamaCloudEnvironment.DEFAULT,
        token: typing.Optional[typing.Union[str, typing.Callable[[], str]]] = None,
        timeout: typing.Optional[float] = None,
        follow_redirects: typing.Optional[bool] = True,
        httpx_client: typing.Optional[httpx.Client] = None,
    ):
        _defaulted_timeout = timeout if timeout is not None else 60 if httpx_client is None else None
        self._client_wrapper = SyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            token=token,
            httpx_client=httpx_client
            if httpx_client is not None
            else httpx.Client(timeout=_defaulted_timeout, follow_redirects=follow_redirects)
            if follow_redirects is not None
            else httpx.Client(timeout=_defaulted_timeout),
            timeout=_defaulted_timeout,
        )
        self.data_sinks = DataSinksClient(client_wrapper=self._client_wrapper)
        self.data_sources = DataSourcesClient(client_wrapper=self._client_wrapper)
        self.embedding_model_configs = EmbeddingModelConfigsClient(client_wrapper=self._client_wrapper)
        self.organizations = OrganizationsClient(client_wrapper=self._client_wrapper)
        self.projects = ProjectsClient(client_wrapper=self._client_wrapper)
        self.files = FilesClient(client_wrapper=self._client_wrapper)
        self.pipelines = PipelinesClient(client_wrapper=self._client_wrapper)
        self.retrievers = RetrieversClient(client_wrapper=self._client_wrapper)
        self.jobs = JobsClient(client_wrapper=self._client_wrapper)
        self.evals = EvalsClient(client_wrapper=self._client_wrapper)
        self.parsing = ParsingClient(client_wrapper=self._client_wrapper)
        self.component_definitions = ComponentDefinitionsClient(client_wrapper=self._client_wrapper)
        self.chat_apps = ChatAppsClient(client_wrapper=self._client_wrapper)
        self.llama_extract = LlamaExtractClient(client_wrapper=self._client_wrapper)
        self.reports = ReportsClient(client_wrapper=self._client_wrapper)


class AsyncLlamaCloud:
    """
    Use this class to access the different functions within the SDK. You can instantiate any number of clients with different configuration that will propagate to these functions.

    Parameters
    ----------
    base_url : typing.Optional[str]
        The base url to use for requests from the client.

    environment : LlamaCloudEnvironment
        The environment to use for requests from the client. from .environment import LlamaCloudEnvironment



        Defaults to LlamaCloudEnvironment.DEFAULT



    token : typing.Optional[typing.Union[str, typing.Callable[[], str]]]
    timeout : typing.Optional[float]
        The timeout to be used, in seconds, for requests. By default the timeout is 60 seconds, unless a custom httpx client is used, in which case this default is not enforced.

    follow_redirects : typing.Optional[bool]
        Whether the default httpx client follows redirects or not, this is irrelevant if a custom httpx client is passed in.

    httpx_client : typing.Optional[httpx.AsyncClient]
        The httpx client to use for making requests, a preconfigured client is used by default, however this is useful should you want to pass in any custom httpx configuration.

    Examples
    --------
    from llama_index import AsyncLlamaCloud

    client = AsyncLlamaCloud(
        token="YOUR_TOKEN",
    )
    """

    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: LlamaCloudEnvironment = LlamaCloudEnvironment.DEFAULT,
        token: typing.Optional[typing.Union[str, typing.Callable[[], str]]] = None,
        timeout: typing.Optional[float] = None,
        follow_redirects: typing.Optional[bool] = True,
        httpx_client: typing.Optional[httpx.AsyncClient] = None,
    ):
        _defaulted_timeout = timeout if timeout is not None else 60 if httpx_client is None else None
        self._client_wrapper = AsyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            token=token,
            httpx_client=httpx_client
            if httpx_client is not None
            else httpx.AsyncClient(timeout=_defaulted_timeout, follow_redirects=follow_redirects)
            if follow_redirects is not None
            else httpx.AsyncClient(timeout=_defaulted_timeout),
            timeout=_defaulted_timeout,
        )
        self.data_sinks = AsyncDataSinksClient(client_wrapper=self._client_wrapper)
        self.data_sources = AsyncDataSourcesClient(client_wrapper=self._client_wrapper)
        self.embedding_model_configs = AsyncEmbeddingModelConfigsClient(client_wrapper=self._client_wrapper)
        self.organizations = AsyncOrganizationsClient(client_wrapper=self._client_wrapper)
        self.projects = AsyncProjectsClient(client_wrapper=self._client_wrapper)
        self.files = AsyncFilesClient(client_wrapper=self._client_wrapper)
        self.pipelines = AsyncPipelinesClient(client_wrapper=self._client_wrapper)
        self.retrievers = AsyncRetrieversClient(client_wrapper=self._client_wrapper)
        self.jobs = AsyncJobsClient(client_wrapper=self._client_wrapper)
        self.evals = AsyncEvalsClient(client_wrapper=self._client_wrapper)
        self.parsing = AsyncParsingClient(client_wrapper=self._client_wrapper)
        self.component_definitions = AsyncComponentDefinitionsClient(client_wrapper=self._client_wrapper)
        self.chat_apps = AsyncChatAppsClient(client_wrapper=self._client_wrapper)
        self.llama_extract = AsyncLlamaExtractClient(client_wrapper=self._client_wrapper)
        self.reports = AsyncReportsClient(client_wrapper=self._client_wrapper)


def _get_base_url(*, base_url: typing.Optional[str] = None, environment: LlamaCloudEnvironment) -> str:
    if base_url is not None:
        return base_url
    elif environment is not None:
        return environment.value
    else:
        raise Exception("Please pass in either base_url or environment to construct the client")
