# SPDX-License-Identifier: Apache-2.0
version: '3'


tasks:
  vllm-pixtral:
    cmds:
      - >
        docker run
        --rm
        --runtime nvidia
        --gpus all
        -p 11435:11435
        -v /mnt/drive/models:/root/.cache/huggingface
        --env "HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}"
        vllm/vllm-openai:latest
        --port 11435
        --model mistralai/Pixtral-12B-2409
        --tokenizer_mode mistral
        --config_format mistral
        --load_format mistral
        --tool-call-parser mistral
        --max-model-len 24000
        --enable-auto-tool-choice
        --served-model-name vision-worker
        --quantization awq
  stop-vllm-pixtral:
    cmds:
      - docker stop vllm-pixtral
  vllm-qwen:
    cmds:
      - >
        docker run
        --rm
        --runtime nvidia
        --gpus all
        -p 11436:11436
        -v /mnt/drive/models:/root/.cache/huggingface
        --env "HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}"
        vllm/vllm-openai:latest
        --port 11436
        --model Qwen/Qwen2.5-VL-7B-Instruct
        --tokenizer_mode auto
        --max-model-len 24000
        --enable-auto-tool-choice
        --tool-call-parser hermes
        --served-model-name vision-worker
        --quantization awq
  stop-vllm-qwen:
    cmds:
      - docker stop vllm-qwen