# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.bad_request_error import BadRequestError
from ...errors.not_found_error import NotFoundError
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.asset_type_enum import AssetTypeEnum
from ...types.encoder_name_enum import EncoderNameEnum
from ...types.error_response import ErrorResponse
from ...types.http_validation_error import HttpValidationError
from ...types.search_result import SearchResult
from ...types.search_type_enum import SearchTypeEnum

try:
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore


class SearchClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def search_dataset(
        self,
        *,
        query: typing.Optional[str] = None,
        queries: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        coactive_image_ids: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        dataset_id: str,
        encoder: typing.Optional[EncoderNameEnum] = None,
        concept_ids: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        metadata_filters: typing.Optional[str] = None,
        asset_type: typing.Optional[AssetTypeEnum] = None,
        search_type: typing.Optional[SearchTypeEnum] = None,
    ) -> SearchResult:
        """
        Perform a visual and audio search of a dataset using a natural language (text) query

        Parameters:
            - query: typing.Optional[str]. The search query

            - queries: typing.Optional[typing.Union[str, typing.List[str]]]. The list of text query strings to include in the natural_language_query

            - coactive_image_ids: typing.Optional[typing.Union[str, typing.List[str]]]. The list of coactive image ids to include in the natural_language_query

            - dataset_id: str. The id of the dataset to search

            - encoder: typing.Optional[EncoderNameEnum]. The encoder to use to search within this dataset.Only applicable if dataset has multiple embeddings.Will use default dataset embedding if None.

            - concept_ids: typing.Optional[typing.Union[str, typing.List[str]]]. The ids of the concepts to include in the natural_language_query

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return

            - metadata_filters: typing.Optional[str]. JSON string containing a list of metadata filters

            - asset_type: typing.Optional[AssetTypeEnum]. Asset type to filter by

            - search_type: typing.Optional[SearchTypeEnum]. Search type to use
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.search.search_dataset(
            dataset_id="dataset_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/search"),
            params=remove_none_from_dict(
                {
                    "query": query,
                    "queries": queries,
                    "coactive_image_ids": coactive_image_ids,
                    "dataset_id": dataset_id,
                    "encoder": encoder,
                    "concept_ids": concept_ids,
                    "offset": offset,
                    "limit": limit,
                    "metadata_filters": metadata_filters,
                    "asset_type": asset_type,
                    "search_type": search_type,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SearchResult, _response.json())  # type: ignore
        if _response.status_code == 400:
            raise BadRequestError(pydantic.parse_obj_as(ErrorResponse, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def search_for_similar_images_in_dataset(
        self,
        *,
        image_public_url: typing.Optional[str] = None,
        coactive_image_id: typing.Optional[str] = None,
        image_path: typing.Optional[str] = None,
        dataset_id: str,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
    ) -> SearchResult:
        """
        Get the images most similar to the image provided within the same dataset

        Parameters:
            - image_public_url: typing.Optional[str]. A public url to an image not in this dataset to use for similarity search

            - coactive_image_id: typing.Optional[str]. A coactive image id in this dataset to use for similarity search

            - image_path: typing.Optional[str]. An image path in this dataset to use for similarity search

            - dataset_id: str. The unique identifier for the dataset

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.search.search_for_similar_images_in_dataset(
            dataset_id="dataset_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/search/similar-images"),
            params=remove_none_from_dict(
                {
                    "image_public_url": image_public_url,
                    "coactive_image_id": coactive_image_id,
                    "image_path": image_path,
                    "dataset_id": dataset_id,
                    "offset": offset,
                    "limit": limit,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SearchResult, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncSearchClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def search_dataset(
        self,
        *,
        query: typing.Optional[str] = None,
        queries: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        coactive_image_ids: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        dataset_id: str,
        encoder: typing.Optional[EncoderNameEnum] = None,
        concept_ids: typing.Optional[typing.Union[str, typing.List[str]]] = None,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        metadata_filters: typing.Optional[str] = None,
        asset_type: typing.Optional[AssetTypeEnum] = None,
        search_type: typing.Optional[SearchTypeEnum] = None,
    ) -> SearchResult:
        """
        Perform a visual and audio search of a dataset using a natural language (text) query

        Parameters:
            - query: typing.Optional[str]. The search query

            - queries: typing.Optional[typing.Union[str, typing.List[str]]]. The list of text query strings to include in the natural_language_query

            - coactive_image_ids: typing.Optional[typing.Union[str, typing.List[str]]]. The list of coactive image ids to include in the natural_language_query

            - dataset_id: str. The id of the dataset to search

            - encoder: typing.Optional[EncoderNameEnum]. The encoder to use to search within this dataset.Only applicable if dataset has multiple embeddings.Will use default dataset embedding if None.

            - concept_ids: typing.Optional[typing.Union[str, typing.List[str]]]. The ids of the concepts to include in the natural_language_query

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return

            - metadata_filters: typing.Optional[str]. JSON string containing a list of metadata filters

            - asset_type: typing.Optional[AssetTypeEnum]. Asset type to filter by

            - search_type: typing.Optional[SearchTypeEnum]. Search type to use
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.search.search_dataset(
            dataset_id="dataset_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/search"),
            params=remove_none_from_dict(
                {
                    "query": query,
                    "queries": queries,
                    "coactive_image_ids": coactive_image_ids,
                    "dataset_id": dataset_id,
                    "encoder": encoder,
                    "concept_ids": concept_ids,
                    "offset": offset,
                    "limit": limit,
                    "metadata_filters": metadata_filters,
                    "asset_type": asset_type,
                    "search_type": search_type,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SearchResult, _response.json())  # type: ignore
        if _response.status_code == 400:
            raise BadRequestError(pydantic.parse_obj_as(ErrorResponse, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def search_for_similar_images_in_dataset(
        self,
        *,
        image_public_url: typing.Optional[str] = None,
        coactive_image_id: typing.Optional[str] = None,
        image_path: typing.Optional[str] = None,
        dataset_id: str,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
    ) -> SearchResult:
        """
        Get the images most similar to the image provided within the same dataset

        Parameters:
            - image_public_url: typing.Optional[str]. A public url to an image not in this dataset to use for similarity search

            - coactive_image_id: typing.Optional[str]. A coactive image id in this dataset to use for similarity search

            - image_path: typing.Optional[str]. An image path in this dataset to use for similarity search

            - dataset_id: str. The unique identifier for the dataset

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.search.search_for_similar_images_in_dataset(
            dataset_id="dataset_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/search/similar-images"),
            params=remove_none_from_dict(
                {
                    "image_public_url": image_public_url,
                    "coactive_image_id": coactive_image_id,
                    "image_path": image_path,
                    "dataset_id": dataset_id,
                    "offset": offset,
                    "limit": limit,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SearchResult, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
