from tensorflow.python.ops import gen_collective_ops as gen_collective_ops
from typing import Any

def all_reduce(t, group_size, group_key, instance_key, merge_op: str = ..., final_op: str = ..., subdiv_offsets=..., communication_hint: str = ..., timeout: int = ...): ...
def all_reduce_v2(t, group_size, group_key, instance_key, merge_op: str = ..., final_op: str = ..., communication_hint: str = ..., timeout: int = ..., ordering_token: Any | None = ..., max_subdivs_per_device: int = ...): ...
def all_gather(t, group_size, group_key, instance_key, communication_hint: str = ..., timeout: int = ...): ...
def all_gather_v2(t, group_size, group_key, instance_key, communication_hint: str = ..., timeout: int = ..., ordering_token: Any | None = ...): ...
def broadcast_send(t, shape, dtype, group_size, group_key, instance_key, communication_hint: str = ..., timeout: int = ...): ...
def broadcast_send_v2(t, group_size, group_key, instance_key, communication_hint: str = ..., timeout: int = ...): ...
def broadcast_recv(shape, dtype, group_size, group_key, instance_key, communication_hint: str = ..., timeout: int = ...): ...
def broadcast_recv_v2(shape, dtype, group_size, group_key, instance_key, communication_hint: str = ..., timeout: int = ...): ...
def initialize_communicator(group_key, rank, group_size, communication_hint: str = ..., timeout_seconds: int = ...): ...
def all_reduce_v3(communicator, t, reduction: str = ..., group_assignment: Any | None = ..., timeout_seconds: Any | None = ...): ...
def all_to_all_v3(communicator, t, group_assignment: Any | None = ..., timeout_seconds: Any | None = ...): ...
