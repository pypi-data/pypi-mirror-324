from tensorflow.python.eager import context as context, function as function
from tensorflow.python.eager.context import get_device_name as get_device_name
from tensorflow.python.framework import config as config, constant_op as constant_op, device as device, dtypes as dtypes, ops as ops
from tensorflow.python.keras import activations as activations, backend as backend
from tensorflow.python.keras.engine.input_spec import InputSpec as InputSpec
from tensorflow.python.keras.layers import recurrent as recurrent
from tensorflow.python.ops import array_ops as array_ops, control_flow_ops as control_flow_ops, gen_cudnn_rnn_ops as gen_cudnn_rnn_ops, math_ops as math_ops, nn as nn, state_ops as state_ops, variables as variables
from tensorflow.python.platform import sysconfig as sysconfig
from tensorflow.python.util.tf_export import keras_export as keras_export
from typing import Any

class _DefunWrapper:
    time_major: Any
    go_backwards: Any
    layer_name: Any
    defun_layer: Any
    def __init__(self, time_major, go_backwards, layer_name) -> None: ...
    def __deepcopy__(self, memo): ...

class GRUCell(recurrent.GRUCell):
    def __init__(self, units, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., kernel_regularizer: Any | None = ..., recurrent_regularizer: Any | None = ..., bias_regularizer: Any | None = ..., kernel_constraint: Any | None = ..., recurrent_constraint: Any | None = ..., bias_constraint: Any | None = ..., dropout: float = ..., recurrent_dropout: float = ..., reset_after: bool = ..., **kwargs) -> None: ...

class GRU(recurrent.DropoutRNNCellMixin, recurrent.GRU):
    def __init__(self, units, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., kernel_regularizer: Any | None = ..., recurrent_regularizer: Any | None = ..., bias_regularizer: Any | None = ..., activity_regularizer: Any | None = ..., kernel_constraint: Any | None = ..., recurrent_constraint: Any | None = ..., bias_constraint: Any | None = ..., dropout: float = ..., recurrent_dropout: float = ..., return_sequences: bool = ..., return_state: bool = ..., go_backwards: bool = ..., stateful: bool = ..., unroll: bool = ..., time_major: bool = ..., reset_after: bool = ..., **kwargs) -> None: ...
    def call(self, inputs, mask: Any | None = ..., training: Any | None = ..., initial_state: Any | None = ...): ...

def standard_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask): ...
def gpu_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths): ...
def gru_with_backend_selection(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask): ...

class LSTMCell(recurrent.LSTMCell):
    def __init__(self, units, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., unit_forget_bias: bool = ..., kernel_regularizer: Any | None = ..., recurrent_regularizer: Any | None = ..., bias_regularizer: Any | None = ..., kernel_constraint: Any | None = ..., recurrent_constraint: Any | None = ..., bias_constraint: Any | None = ..., dropout: float = ..., recurrent_dropout: float = ..., **kwargs) -> None: ...

class LSTM(recurrent.DropoutRNNCellMixin, recurrent.LSTM):
    return_runtime: Any
    state_spec: Any
    def __init__(self, units, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., unit_forget_bias: bool = ..., kernel_regularizer: Any | None = ..., recurrent_regularizer: Any | None = ..., bias_regularizer: Any | None = ..., activity_regularizer: Any | None = ..., kernel_constraint: Any | None = ..., recurrent_constraint: Any | None = ..., bias_constraint: Any | None = ..., dropout: float = ..., recurrent_dropout: float = ..., return_sequences: bool = ..., return_state: bool = ..., go_backwards: bool = ..., stateful: bool = ..., time_major: bool = ..., unroll: bool = ..., **kwargs) -> None: ...
    def call(self, inputs, mask: Any | None = ..., training: Any | None = ..., initial_state: Any | None = ...): ...

def standard_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask): ...
def gpu_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths): ...
def lstm_with_backend_selection(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask): ...
def is_sequence_right_padded(mask): ...
def has_fully_masked_sequence(mask): ...
def is_cudnn_supported_inputs(mask, time_major): ...
def calculate_sequence_by_mask(mask, time_major): ...
