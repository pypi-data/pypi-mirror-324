from tensorflow.python.eager import context as context
from tensorflow.python.framework import dtypes as dtypes, ops as ops, tensor_shape as tensor_shape, tensor_spec as tensor_spec, tensor_util as tensor_util
from tensorflow.python.keras import backend as backend
from tensorflow.python.keras.engine import base_preprocessing_layer as base_preprocessing_layer
from tensorflow.python.keras.layers.preprocessing import category_encoding as category_encoding, table_utils as table_utils
from tensorflow.python.keras.saving.saved_model import layer_serialization as layer_serialization
from tensorflow.python.keras.utils import layer_utils as layer_utils, tf_utils as tf_utils
from tensorflow.python.ops import array_ops as array_ops, control_flow_ops as control_flow_ops, init_ops as init_ops, lookup_ops as lookup_ops, math_ops as math_ops, sparse_ops as sparse_ops, string_ops as string_ops
from tensorflow.python.platform import gfile as gfile
from tensorflow.python.util import compat as compat
from typing import Any

INT: str
MULTI_HOT: str
ONE_HOT: str
COUNT: str
TF_IDF: str

class _NullInitializer(lookup_ops.TextFileInitializer):
    def __init__(self, key_dtype, value_dtype) -> None: ...
    @property
    def key_dtype(self): ...
    @property
    def value_dtype(self): ...
    def initialize(self, table) -> None: ...

class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):
    invert: Any
    max_tokens: Any
    num_oov_indices: Any
    output_mode: Any
    sparse: Any
    pad_to_max_tokens: Any
    mask_token: Any
    oov_token: Any
    tf_idf_weights: Any
    def __init__(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary: Any | None = ..., invert: bool = ..., output_mode=..., sparse: bool = ..., pad_to_max_tokens: bool = ..., **kwargs): ...
    def compute_output_shape(self, input_shape): ...
    def compute_output_signature(self, input_spec): ...
    def adapt(self, data, reset_state: bool = ...) -> None: ...
    def get_vocabulary(self, include_special_tokens: bool = ...): ...
    def vocabulary_size(self): ...
    def vocab_size(self): ...
    def get_config(self): ...
    def count_params(self): ...
    def set_vocabulary(self, vocabulary, idf_weights: Any | None = ...) -> None: ...
    def call(self, inputs): ...

class _IndexLookupAccumulator: ...

class _IndexLookupCombiner(base_preprocessing_layer.Combiner):
    def __init__(self, vocab_size: Any | None = ..., mask_value: Any | None = ..., oov_value: Any | None = ..., compute_idf: bool = ...) -> None: ...
    def compute(self, values, accumulator: Any | None = ...): ...
    def merge(self, accumulators): ...
    def extract(self, accumulator): ...
    def restore(self, output) -> None: ...
    def serialize(self, accumulator): ...
    def deserialize(self, encoded_accumulator): ...
