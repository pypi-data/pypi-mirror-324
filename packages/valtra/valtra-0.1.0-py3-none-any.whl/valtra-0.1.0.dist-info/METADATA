Metadata-Version: 2.2
Name: valtra
Version: 0.1.0
Summary: A dynamic dataset loader for PyTorch.
Home-page: https://github.com/marcosousapoza/valtra
Author: Marco Sousa-Poza
Author-email: Marco Sousa-Poza <marco.sousapoza@gmail.com>
Project-URL: Homepage, https://github.com/marcosousapoza/valtra
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch
Dynamic: author
Dynamic: home-page
Dynamic: requires-python

# Valtra (Validation - Train)

Valtra is a mini-project I created because I got sick of keeping track of train and validation/test datasets separately.  
It dynamically switches between training and validation/test data using a simple wrapper around PyTorchâ€™s `DataLoader`.

## ðŸ“Œ Why "Valtra"?
The name comes from **Val**idation and **Tra**in. Plus, it has a nice ring to it.

## ðŸš€ Installation
```bash
pip install valtra
```

## ðŸ”§ Usage
```python
import torch
from valtra.dataloader import DynamicDataLoader
from valtra.utils import split_dataset

# Create dummy data
data = torch.randn(1000, 10)
labels = torch.randint(0, 5, (1000,))
dataset = torch.utils.Dataset(data, labels)

# Create DynamicDataLoader
dataloader = split_dataset(dataset, split_ratio=0.8, batch_size=32)

# Training loop (default behavior is training mode)
for batch in dataloader(train=True):
    print("Train batch:", batch[0].shape)

# Evaluation loop
for batch in dataloader(test=True):
    print("Test batch:", batch[0].shape)

# Evaluation loop
for batch in dataloader(other=True):
    print("Other batch:", batch[0].shape)
```

## Contribution
There are many ways to make code more readable in `torch`. If you have another idea feel free to contact me or create an issue!

## ðŸ“œ License
MIT License
