# AUTOGENERATED! DO NOT EDIT! File to edit: ../../modules_nbs/workflow_run_jobs.ipynb.

# %% auto 0
__all__ = ['flt_params', 'check_tasks', 'get_sq', 'get_jobsn', 'is_q_empty', 'read_dict', 'to_dict', 'submit_job', 'SLURMJob',
           'has_slurm', 'to_sbatch_script', 'parse_time', 'get_tried_job_keys', 'feed_jobs', 'run_jobs']

# %% ../../modules_nbs/workflow_run_jobs.ipynb 3
import logging
import os
from pathlib import Path
import subprocess
import time

from tqdm import tqdm
# from pprint import pprint

from roux.lib.str import encode, decode
from roux.lib.sys import run_com
# from roux.workflow.task import flt_params

from datetime import datetime, timedelta
    
def flt_params(
    parameters_list,
    force=False,
    verbose=False,
    out_type=None,
):
    before = len(parameters_list)
    if isinstance(parameters_list,list):
        ## TODO: use `to_outp`?
        parameters_list_flt = [
            d
            for d in parameters_list
            if (force if force else not Path(d["output_path"]).exists())
        ]
    elif isinstance(parameters_list,dict):
        parameters_list_flt ={ 
            k:d
            for k,d in parameters_list.items()
            if (force if force else not Path(d["output_path"]).exists())
        }
    else:
        raise ValueError(type(parameters_list))
    if not force:
        if before - len(parameters_list_flt) != 0:
            logging.info(
                f"parameters_list_flt reduced because force=False: {before} -> {len(parameters_list_flt)}"
            )
    if out_type == 'list':
        if isinstance(parameters_list_flt,dict):
            parameters_list_flt=list(parameters_list_flt.values())
#     if verbose:
#         # check_tasks
#         outps=[pms['output_path'] for pms in parameters_list]
#         outps_flt=[pms['output_path'] for pms in parameters_list_flt]
            
#         for outp in outps:
#             print(f"{not outp in outps_flt} :{outp}")
            
    return parameters_list_flt

# from functools import partial
def check_tasks(
    params,
    ):
    if isinstance(params,str):
        params=read_dict(params)
        
    if isinstance(params,dict):
        params=list(params.values())

    flt_params(
        params,
        verbose=True,
        out_type='list',    
    )

def get_sq(
    user=None,
    ):
    # Build the squeue command
    # --format="%.18i %.9P %.30j %.8u %.8T %.10M %.9l %.6D %R"
    
    return run_com(
        'sq --format="%.18i%.100j"' + (f'-u {user}' if not user is None else ''),
        verbose=False,
    )
    
def get_jobsn(
    user=None,
    verbose=False,
    ):
    lines = get_sq(
        user=user,
    ).splitlines()
    lines=[s for s in lines if not "spawner-jupyte" in s]
    if verbose:
        print(len(lines),lines)
    return len(lines)

def is_q_empty(
    user=None,
    verbose=False,
    ):
    """Check if the SLURM job queue is empty for a specific user (or globally)."""
    return get_jobsn(
        user=user,
        verbose=verbose,    
    ) == 0  # No jobs, just the header

def read_dict(
    p,
    **kws,
    ):
    import yaml

    with open(p, "r") as f:
        d1 = yaml.safe_load(f, **kws)
    return d1 if d1 is not None else {}

def to_dict(
    d,
    p,
    **kws,
    ):
    import yaml
    with open(p, "w") as f:
        yaml.safe_dump(d, f, **kws)
    return p

def submit_job(p):
    """Submit a SLURM job using sbatch."""
    job_name=f"sluf:{Path(p).stem}"
    if job_name in get_sq():
        logging.error(f"skipped because already running: {job_name}.")
        return 
    
    com = f'sbatch {p}'
    res=run_com(com)
    # Submitted batch job 3325831
    job_id=res.rsplit(' ')[-1]
    logging.info(f"job_id={job_id}")
    return job_id

class SLURMJob:
    def __init__(
        self, 
        job_name, 
        log_path, 
        
        mem="4G", 
        cpus=4, 
        time="01:00:00", 
        ## not used often
        ntasks=1, 
        partition="default"
        ):
        
        self.job_name = job_name
        self.output = log_path
        self.time = time
        self.cpus = cpus
        self.mem = mem
        self.ntasks = ntasks
        self.partition = partition
        self.commands = []

    def add_command(self, command):
        """Add a command to be executed in the SLURM script"""
        self.commands.append(command)

    def write_script(
        self,
        # com=None,
        outp,
        
        job_pre=None,
        modules=None,
        packages=None,
        
        ):
        """Generate the SLURM script"""
        
        # assert not (com is None and outp is None)
        
        # if outp is None and not com is None:
        #     outp=f".slurm/{encode(com)}.sh"
        modules_load_str=''
        packages_install_str=''
        
        if job_pre is None:
            job_pre='## not job_pre provided'
        
        if not modules is None:
            if len(modules)>0:
                modules_load_str+="module load "+(' '.join(modules))
        
        if not packages is None:
            if len(packages)>0:
                packages_install_str+="pip install "+(' '.join(packages))
        
        with open(outp, 'w') as f:
            f.write(
#SBATCH --partition={self.partition}
f"""#!/bin/bash
#SBATCH --job-name={self.job_name}
#SBATCH --err={self.output}/%j.err
#SBATCH --output={self.output}/%j.out                
#SBATCH --time={self.time}
#SBATCH --ntasks={self.ntasks}
#SBATCH --cpus-per-task={self.cpus}
#SBATCH --mem={self.mem}

{job_pre}

{modules_load_str}

{packages_install_str}

""")
            for command in self.commands:
                f.write(f"{command}\n")
                
            # f.write("exit(0)\n")
            
    def submit(self, outp):
        """Submit a SLURM job using sbatch."""
        submit_job(outp)
    
def has_slurm(
    ):
    return run_com('sbatch --help',returncodes=[0,1,127])!=''

def to_sbatch_script(
    sbatch_path,
    pms,
    script_path,
    script_pre,
    
    job_pre,
    modules,
    packages,

    mem,# "5gb",
    cpus,# 1,
    time,# "01:00:00",
    
    test=False,
    **kws_job,
):
    sbatch_dir_path=Path(sbatch_path).with_suffix("").as_posix()
    params_path=f"{sbatch_dir_path}/params.yaml"
    log_dir_path=f"{sbatch_dir_path}/logs/"

    Path(sbatch_dir_path).mkdir(parents=True,exist_ok=True)
    Path(log_dir_path).mkdir(parents=True,exist_ok=True)

    ## save parameters
    to_dict(
        pms,
        params_path,
    )
    if test:
        logging.info(f"params_path={params_path}")

    ## create command
    if script_path.endswith('.sh'):
        com=f"{script_pre}{'bash ' if not script_path.startswith('bash ') else ''}{script_path} {params_path}"
        # pass
        # return "under dev"
    else:
        # if not any([s.startswith('python') for s in modules]):
        #     modules.append('python')

        if script_path.endswith('.py'):
            com=f"{script_pre}{'python ' if not script_path.startswith('python ') else ''}{script_path} --cfg {params_path}"
            # packages.append('argh')
            # pass
            # return "under dev"

        elif script_path.endswith('.ipynb'):
            log_path=f"{log_dir_path}/{Path(script_path).name}"
            com=(
                f"{script_pre}papermill --parameters_file {params_path} "
                f"--stdout-file {Path(log_path).with_suffix('.out')} --stderr-file {Path(log_path).with_suffix('.err')} "
                # kernel_name=kernel,
                "--start-timeout=600 "
                "--report-mode "
                # "--allow_errors=False "
                f"{script_path} {log_path}"
            )
            # --kernel
            # packages.append('papermill')
            # return "under dev"
            # Using -b or --parameters_base64, users can provide a YAML string, base64-encoded, containing parameter values.
            # $ papermill local/input.ipynb s3://bkt/output.ipynb -b YWxwaGE6IDAuNgpsMV9yYXRpbzogMC4xCg==
        else:
            raise ValueError(script_path)

    if test:
        logging.info(com)

    # write the slurm script 
    job = SLURMJob(
        job_name=f"sluf:{Path(sbatch_path).stem}",
        log_path=log_dir_path,

        mem=mem,#"4G",
        cpus=cpus,#3,
        time=time,#"01:00:00",

        **kws_job,
    )
    # include run_multi()
    # import inspect
    # inspect.getsource(func)        
    job.add_command(com)

    job.write_script(
        sbatch_path,
        job_pre=job_pre,
        modules=modules,
        packages=packages,
    )
    return sbatch_path

def parse_time(duration_str):
    """
    Parse a string like '4h', '30m', or '2d' into a timedelta object.
    """
    time_map = {
        'h': 'hours',
        'm': 'minutes',
        's': 'seconds',
        'd': 'days',
    }
    unit = duration_str[-1]  # Last character indicates the unit
    value = int(duration_str[:-1])  # Everything before the last character is the value

    if unit not in time_map:
        raise ValueError(f"Invalid time unit: {unit}. Use 'h', 'm', 's', or 'd'.")

    return timedelta(**{time_map[unit]: value})

def get_tried_job_keys(
    cache_dir_path
    ):
    from roux.lib.io import read_ps
    # cache_dir_path='.sluf/'
    return list(set([Path(p).parent.parent.stem for p in read_ps(f'{cache_dir_path}/*/logs/*.out')]))

def feed_jobs(
    com,
    
    # user,
    feed_duration,
    feed_interval='10m',
    jobs=200, # feed each time

    feed_if_jobs_max=0.5, ## wait till this many jobs are on q
    
    jobs_max=1000,
    test=False,
    force=False,
    
    kws_run_jobs={},
):
    """Monitor SLURM queue and submit new jobs when queue is empty."""        
    duration = parse_time(feed_duration)
    interval = parse_time(feed_interval)
    
    start_time = datetime.now()
    end_time = start_time + duration

    print(f"Start Time: {start_time}")
    print(f"End Time: {end_time}")

    i=0
    while datetime.now() < end_time:
        
        remaining = end_time - datetime.now()
        # Print only every second
        # if remaining.total_seconds() % 600 == 0:
        print(f"Time remaining: {remaining}", end='\r')  
                    
        if get_jobsn()<=(jobs*feed_if_jobs_max) and get_jobsn()<jobs_max:
            print(f"submitting new jobs...")

            if isinstance(com,str):
                if com.endswith('.yaml'):

                    logging.info("yaml config found")
                    # params=read_dict(com)
                    com=list(read_dict(com).values())
                    
                else:            
                    if not test:
                        if Path(com).exists():
                            submit_job(com)
                            
                        else:
                            run_com(
                                com
                            )
                    continue
            
            if isinstance(com,list): 
                params=com
                if i*jobs < len(params):
                    run_jobs(
                        params=params[(i)*jobs:(i+1)*jobs],
                        **kws_run_jobs,
                        # **{'testn':jobs},
                    )
                    i+=1
                else:
                    print("\nall jobs processed!")
                    break

        print(f"{get_jobsn()} jobs are still running, waiting for {interval}s and jobs <= {jobs*feed_if_jobs_max} ..")
        time.sleep(interval.total_seconds())
        
    print("\nDuration elapsed!")

def run_jobs(
    script_path : str, ## preffix
    params,
    
    script_pre : str ='', ## e.g. micromamba run -n env
    
    mem : str ="5gb",
    cpus : str =1,
    time : str ="01:00:00",
    
    ## deps
    job_pre : str = None, 
    modules : list =[],
    packages : list =[],
    
    force : bool =False,
    force_setup : bool =False,
    test1 : bool =False,
    testn : int =None,
    test : bool =False,

    feedn : int =None,
    feed_duration : str ='1h', #hr 
    feed_interval : str ='10m',
    feed_if_jobs_max : float =0.5,
    
    cache_dir_path='.sluf/',
    
    **kws_job,
):    
    """
    Run multipliers.

    Usage: 
        Higher level to the run_tasks
    """    
    # print(type(testn))
    
    ## get reduced list of inputs fromm task
    if isinstance(params,str):
        params=read_dict(params)
    if isinstance(params,dict):
        params=list(params.values())
        
    params=flt_params(
            params,
            force=force,
        )

    assert all(['input_path' in pms for pms in params])
    assert all(['output_path' in pms for pms in params])

    if not test: 
        test=not has_slurm()
        if test:
            logging.warning("slurm not available; running bash in test mode ..")
        else:
            logging.info("slurm found ..")
    
    if not feedn is None and not test:
        ## recursive
        assert isinstance(feedn,int), feedn
        
        kws_run_jobs={
            **dict(
                script_path= script_path, #, ## preffix
                script_pre= script_pre, #='', ## e.g. micromamba run -n env

                mem= mem, #="5gb",
                cpus= cpus, #=1,
                time= time, #="01:00:00",

                ## deps
                modules= modules, #=[],
                packages= packages, #=[],

                force= force, #=False,
                force_setup= force_setup, #=False,
                test1= test1, #=False,
                testn= testn, #=None,
                test= test, #=False,
            ),
            **kws_job,
        }
        
        ## each round feed feedn jobs from run_jobs
        # from random import shuffle
        # shuffle(params)
        if isinstance(params,dict):
            job_keys_tried=get_tried_job_keys(
                cache_dir_path
            )
            logging.info(f"found {len(job_keys_tried)} tried jobs, they will be deprioritized.")
            params={
                **{k:d for k,d in params.items() if not k in job_keys_tried},
                **{k:d for k,d in params.items() if k in job_keys_tried},
            }
        
        feed_jobs(
            com=params, ## all
            jobs=feedn, ## feed each time
            # user=user,
            feed_duration=feed_duration,
            feed_interval=feed_interval,
            feed_if_jobs_max=feed_if_jobs_max,
            
            test=test,            
            
            kws_run_jobs=kws_run_jobs,
        )
        
        return
    
    logging.info("q.ing jobs.. ")
    
    sbatch_paths=[]
    params_jobs={}
    job_ids=[]
    
    if not testn is None:
        params=params[:testn]
        logging.warning(f"filtered to {len(params)} jobs ..")
        
    for pms in tqdm(params):
        key=encode(
            pms,#['output_path']
            short=True,
        )
        
        sbatch_path=f"{cache_dir_path}/{key}.sh"
        
        if not Path(sbatch_path).exists() or force_setup:
            if test:
                logging.warning("forcing setup (re-rewiting the sbatch scripts)..")
            job=to_sbatch_script(
                sbatch_path=sbatch_path,
                pms=pms,
                script_path=script_path,
                script_pre=script_pre,
                
                job_pre=job_pre,
                modules=modules,
                packages=packages,
                
                mem=mem,# "5gb",
                cpus=cpus,# 1,
                time=time,# "01:00:00",
                
                test=test,
                **kws_job,
            )
    
        if not test:
            # submit the jobs
            job_ids.append(
                submit_job(
                    sbatch_path
                )
            )
            
        if test:
            run_com(
                f"bash {sbatch_path} &> {cache_dir_path}/stdout",
                )
        sbatch_paths.append(sbatch_path)
        params_jobs[sbatch_path]=pms
        
    params_jobs_path=f"{cache_dir_path}/{encode(params_jobs,short=True)}.yaml"
    
    to_dict(
        params_jobs,
        params_jobs_path,
    )
    
    # logging.info("jobs submitted.")
    if not test:
        logging.info(get_sq())  
    return params_jobs_path
