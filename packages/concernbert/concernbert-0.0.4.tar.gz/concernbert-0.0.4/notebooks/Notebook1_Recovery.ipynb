{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from concernbert.latex import dataframe_to_latex\n",
    "from concernbert.selection import EntityTree, open_db\n",
    "from concernbert.semantic import find_method_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(db_path: str, filenames: list[str]) -> list[str]:\n",
    "    with open_db(db_path) as conn:\n",
    "        trees = EntityTree.load_from_db(conn.cursor())\n",
    "    contents = []\n",
    "    for filename in filenames:\n",
    "        contents.append(trees[filename].text())\n",
    "    return contents\n",
    "\n",
    "\n",
    "def clean_whitespace(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "\n",
    "def normalize_vectors(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize each vector in X to have a unit length, handle zero-norm vectors.\"\"\"\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "    # Prevent division by zero by replacing zero norms with 1 (to avoid NaNs)\n",
    "    norms[norms == 0] = 1\n",
    "\n",
    "    return X / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files created by recovery.py\n",
    "df = pd.read_csv(\"_data/recovery.csv\", index_col=0)\n",
    "\n",
    "with open(\"_data/recovery_state.pkl\", \"rb\") as f:\n",
    "    state = pickle.load(f)\n",
    "\n",
    "tests: dict[str, dict[int, list[list[str]]]] = state[\"tests\"]\n",
    "filenames: dict[str, list[str]] = state[\"filenames\"]\n",
    "lsi_embeddings: dict[str, dict[int, dict[str, np.ndarray]]] = state[\"lsi_embeddings\"]\n",
    "d2v_embeddings: dict[str, dict[int, dict[str, np.ndarray]]] = state[\"d2v_embeddings\"]\n",
    "bert_embeddings: dict[str, dict[str, np.ndarray]] = state[\"bert_embeddings\"]\n",
    "\n",
    "# Split \"model\" into \"model\" and \"dim\"\n",
    "df[\"model\"] = df[\"model\"].astype(str)\n",
    "df[[\"model\", \"dim\"]] = df[\"model\"].str.split(\"-\", n=1, expand=True)\n",
    "df[\"dim\"] = pd.to_numeric(df[\"dim\"], errors=\"coerce\").fillna(768).astype(int)\n",
    "columns = list(df.columns)\n",
    "model_index = columns.index(\"model\")\n",
    "new_order = columns[: model_index + 1] + [\"dim\"] + columns[model_index + 1 : -1]\n",
    "df = df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(list(it.chain(*filenames.values())))\n",
    "print(f\"# of Files: {n_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "\n",
    "for db_path in tests:\n",
    "    for group_size in [2, 3, 4, 5]:\n",
    "        counts[group_size] += len(tests[db_path][group_size])\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby([\"model\", \"dim\", \"group_size\"])[\"nmi\"].mean().reset_index()\n",
    "summary_df = grouped_df.pivot_table(\n",
    "    index=[\"model\", \"dim\"], columns=\"group_size\", values=\"nmi\"\n",
    ").reset_index()\n",
    "summary_df.columns = [\"Model\", \"Dim.\", \"NMI-2\", \"NMI-3\", \"NMI-4\", \"NMI-5\"]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_tests = []\n",
    "\n",
    "for (db_path, group_i), _ in df[df[\"group_size\"] == 2].groupby([\"db_path\", \"group_i\"]):\n",
    "    group = tests[db_path][2][group_i]\n",
    "    pair_tests.append([db_path] + group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 14933\n",
    "SEED = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labels = None\n",
    "point_labels = None\n",
    "docs = None\n",
    "\n",
    "\n",
    "# Function to plot the diagram\n",
    "def plot_diagram(ax, db_path: str, group: list[str], model: str):\n",
    "    texts = load_files(db_path, group)\n",
    "    nested_docs = [\n",
    "        [clean_whitespace(d.method_text) for d in find_method_docs(t)] for t in texts\n",
    "    ]\n",
    "    docs = list(it.chain(*nested_docs))\n",
    "\n",
    "    # Dumb hack to get the emb_dict for a model name\n",
    "    parts = model.split(\"-\")\n",
    "    normalize = True\n",
    "    if len(parts) == 1:\n",
    "        if parts[0].lower() == \"bert\":\n",
    "            normalize = False\n",
    "            emb_dict = bert_embeddings[db_path]\n",
    "        else:\n",
    "            raise RuntimeError\n",
    "    elif len(parts) == 2:\n",
    "        if parts[0].lower() == \"lsi\":\n",
    "            emb_dict = lsi_embeddings[db_path][int(parts[1])]\n",
    "        elif parts[0].lower() == \"d2v\":\n",
    "            emb_dict = d2v_embeddings[db_path][int(parts[1])]\n",
    "        else:\n",
    "            raise RuntimeError()\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    # Plot\n",
    "    embs: list[np.ndarray] = []\n",
    "    labels: list[str] = []\n",
    "    for i, filename in enumerate(group):\n",
    "        emb = emb_dict[filename]\n",
    "        embs.extend(emb)\n",
    "        labels.extend([str(i)] * emb.shape[0])\n",
    "    emb = np.vstack(embs)\n",
    "    if normalize:\n",
    "        emb = normalize_vectors(emb)\n",
    "    emb_2d = MDS(random_state=SEED).fit_transform(emb)\n",
    "\n",
    "    # lol\n",
    "    point_labels = [\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"a\",\n",
    "        \"b\",\n",
    "        \"c\",\n",
    "        \"d\",\n",
    "        \"e\",\n",
    "        \"f\",\n",
    "        \"g\",\n",
    "        \"h\",\n",
    "        \"i\",\n",
    "        \"j\",\n",
    "        \"k\",\n",
    "    ]\n",
    "    # point_labels = list(string.ascii_lowercase)\n",
    "\n",
    "    marker_styles = {\"0\": \"o\", \"1\": \"s\"}\n",
    "    marker_colors = {\"0\": \"#90afd5\", \"1\": \"#f9ab6c\"}\n",
    "\n",
    "    # Adjust the offset for text labels\n",
    "    x_offset = 0.0\n",
    "    y_offset = -0.005\n",
    "\n",
    "    # Add labels to each point first\n",
    "    for i in range(emb_2d.shape[0]):\n",
    "        ax.text(\n",
    "            emb_2d[i, 0] + x_offset,  # Add the x offset\n",
    "            emb_2d[i, 1] + y_offset,  # Add the y offset\n",
    "            point_labels[i],\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",  # Make the text bold\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"#333333\",  # Adjust the color if necessary\n",
    "        )\n",
    "\n",
    "    # Now plot the scatter plot after the text, so markers can overlap text if needed\n",
    "    sns.scatterplot(\n",
    "        x=emb_2d[:, 0],\n",
    "        y=emb_2d[:, 1],\n",
    "        hue=labels,\n",
    "        style=labels,\n",
    "        markers=marker_styles,\n",
    "        palette=marker_colors,\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "        edgecolor=\"black\",\n",
    "        s=125,\n",
    "    )\n",
    "\n",
    "    # Remove ticks\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    global my_labels\n",
    "    my_labels = labels\n",
    "    global my_point_labels\n",
    "    my_point_labels = point_labels\n",
    "    global my_docs\n",
    "    my_docs = docs\n",
    "\n",
    "\n",
    "db_path, a, b = pair_tests[INDEX]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "plot_diagram(axes[0], db_path, [a, b], \"BERT\")\n",
    "plot_diagram(axes[1], db_path, [a, b], \"LSI-256\")\n",
    "plot_diagram(axes[2], db_path, [a, b], \"D2V-256\")\n",
    "\n",
    "axes[0].set_title(\"ConcernBERT\", fontsize=10)\n",
    "axes[1].set_title(\"LSI\", fontsize=10)\n",
    "axes[2].set_title(\"Doc2Vec\", fontsize=10)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"black\")\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"_data/embeddings.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "def escape(text: str) -> str:\n",
    "    text = text.replace(\"{\", r\"\\{\")\n",
    "    text = text.replace(\"}\", r\"\\}\")\n",
    "    text = text.replace(\"_\", r\"\\_\")\n",
    "    return text\n",
    "\n",
    "\n",
    "for i, label in enumerate(my_labels):\n",
    "    letter = my_point_labels[i]\n",
    "    limit = 80\n",
    "    text = my_docs[i]\n",
    "    if len(text) > limit:\n",
    "        text = escape(text[:limit])\n",
    "        text = f\"\\\\texttt{{{text}...}}\"\n",
    "    else:\n",
    "        text = escape(text)\n",
    "        text = f\"\\\\texttt{{{text}}}\"\n",
    "    rows.append({\"Marker\": letter, \"Text\": text})\n",
    "\n",
    "text_df = pd.DataFrame.from_records(rows)\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dataframe_to_latex(\n",
    "    text_df, \"Methods in Figure 1\", \"tbl:methods\", col_format=\"r|l\"\n",
    ")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
