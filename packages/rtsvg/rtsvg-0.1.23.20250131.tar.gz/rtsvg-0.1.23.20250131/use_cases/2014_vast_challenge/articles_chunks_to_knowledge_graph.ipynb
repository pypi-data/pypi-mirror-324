{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "def promptModel(prompt, model):\n",
    "    response: ChatResponse = chat(model=model, messages=[{ 'role': 'user', 'content': prompt,},])\n",
    "    return response['message']['content']\n",
    "\n",
    "_dir_ = '../../../data/2014_vast/MC1/'\n",
    "df = df_articles = pd.read_parquet(_dir_ + 'articles.parquet')\n",
    "def extractPythonBlock(s):\n",
    "    _start_, _end_ = '```python', '```'\n",
    "    if _start_ in s and _end_ in s[s.index(_start_)+len(_start_):]:\n",
    "        i0 = s.index(_start_)+len(_start_)\n",
    "        i1 = s.index(_end_, i0)\n",
    "        return s[i0:i1]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_deepseek_responses_ = _dir_ + '20250201_deep_seek_responses.parquet'\n",
    "if os.path.exists(_file_deepseek_responses_) == False:\n",
    "    _response_lu_, _timing_lu_ = {}, {}\n",
    "    _model_ = 'deepseek-r1:14b'\n",
    "    total_files     = df['file'].nunique()\n",
    "    files_processed = 0\n",
    "    for k, k_df in df.groupby('file'):\n",
    "        if k in _response_lu_:\n",
    "            files_processed += 1 \n",
    "            continue\n",
    "        k_df             = k_df.sort_values('sentence_no').reset_index()\n",
    "        _article_        = ''.join(k_df['sentence'])\n",
    "        t0               = time.time()\n",
    "        _response_       = promptModel(f'Extract all of the entities into a Python dictionary from the following article.  The dictionary pairing should indicate the entities type:\\n\\n{_article_}', _model_)\n",
    "        _timing_lu_[k]   = time.time() - t0\n",
    "        _response_lu_[k] = _response_\n",
    "        print('.', end='')\n",
    "        if files_processed % 10 == 0:\n",
    "            print(f'{files_processed}/{total_files}', end='')\n",
    "            _file_save_info_ = {'file':[], 'deep_seek_response':[], 'time_taken':[]}\n",
    "            for _keyvalue_ in _response_lu_:\n",
    "                _file_save_info_['file'].append(_keyvalue_)\n",
    "                _file_save_info_['deep_seek_response'].append(_response_lu_[_keyvalue_])\n",
    "                _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "            df_intermediate = pd.DataFrame(_file_save_info_)\n",
    "            df_intermediate.to_parquet('INTERMEDIA_deep_seek_responses.parquet')\n",
    "        files_processed += 1\n",
    "    _file_save_info_ = {'file':[], 'deep_seek_response':[], 'time_taken':[]}\n",
    "    for _keyvalue_ in _response_lu_:\n",
    "        _file_save_info_['file'].append(_keyvalue_)\n",
    "        _file_save_info_['deep_seek_response'].append(_response_lu_[_keyvalue_])\n",
    "        _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "    df_final = pd.DataFrame(_file_save_info_)\n",
    "    df_final.to_parquet(_file_deepseek_responses_)\n",
    "df_deepseek          = pd.read_parquet(_file_deepseek_responses_)\n",
    "df_deepseek          = df_deepseek.rename({'deep_seek_response':'model_response'}, axis=1)\n",
    "df_deepseek['model'] = 'deepseek-r1:14b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_response_lu_, _timing_lu_ = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_llama32_responses_ = _dir_ + '20250201_llama32_responses.parquet'\n",
    "if os.path.exists(_file_llama32_responses_) == False:\n",
    "    _model_ = 'llama3.2'\n",
    "    total_files     = df['file'].nunique()\n",
    "    files_processed = 0\n",
    "    for k, k_df in df.groupby('file'):\n",
    "        if k in _response_lu_:\n",
    "            files_processed += 1 \n",
    "            continue\n",
    "        k_df             = k_df.sort_values('sentence_no').reset_index()\n",
    "        _article_        = ''.join(k_df['sentence'])\n",
    "        t0               = time.time()\n",
    "        _response_       = promptModel(f'Extract all of the entities into a Python dictionary from the following article.  The dictionary pairing should indicate the entities type:\\n\\n{_article_}', _model_)\n",
    "        _timing_lu_[k]   = time.time() - t0\n",
    "        _response_lu_[k] = _response_\n",
    "        print('.', end='')\n",
    "        if files_processed % 10 == 0:\n",
    "            print(f'{files_processed}/{total_files}', end='')\n",
    "            _file_save_info_ = {'file':[], 'llama32_response':[], 'time_taken':[]}\n",
    "            for _keyvalue_ in _response_lu_:\n",
    "                _file_save_info_['file'].append(_keyvalue_)\n",
    "                _file_save_info_['llama32_response'].append(_response_lu_[_keyvalue_])\n",
    "                _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "            df_intermediate = pd.DataFrame(_file_save_info_)\n",
    "            df_intermediate.to_parquet('INTERMEDIA_llama32_responses.parquet')\n",
    "        files_processed += 1\n",
    "    _file_save_info_ = {'file':[], 'llama32_response':[], 'time_taken':[]}\n",
    "    for _keyvalue_ in _response_lu_:\n",
    "        _file_save_info_['file'].append(_keyvalue_)\n",
    "        _file_save_info_['llama32_response'].append(_response_lu_[_keyvalue_])\n",
    "        _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "    df_final = pd.DataFrame(_file_save_info_)\n",
    "    df_final.to_parquet(_file_llama32_responses_)\n",
    "df_llama32          = pd.read_parquet(_file_llama32_responses_)\n",
    "df_llama32          = df_llama32.rename({'llama32_response':'model_response'}, axis=1)\n",
    "df_llama32['model'] = 'llama32:3b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_response_lu_, _timing_lu_ = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_phi4_responses_ = _dir_ + '20250201_phi4_responses.parquet'\n",
    "if os.path.exists(_file_phi4_responses_) == False:\n",
    "    _model_ = 'phi4'\n",
    "    total_files     = df['file'].nunique()\n",
    "    files_processed = 0\n",
    "    for k, k_df in df.groupby('file'):\n",
    "        if k in _response_lu_:\n",
    "            files_processed += 1 \n",
    "            continue\n",
    "        k_df             = k_df.sort_values('sentence_no').reset_index()\n",
    "        _article_        = ''.join(k_df['sentence'])\n",
    "        t0               = time.time()\n",
    "        _response_       = promptModel(f'Extract all of the entities into a Python dictionary from the following article.  The dictionary pairing should indicate the entities type:\\n\\n{_article_}', _model_)\n",
    "        _timing_lu_[k]   = time.time() - t0\n",
    "        _response_lu_[k] = _response_\n",
    "        print('.', end='')\n",
    "        if files_processed % 10 == 0:\n",
    "            print(f'{files_processed}/{total_files}', end='')\n",
    "            _file_save_info_ = {'file':[], 'phi4_response':[], 'time_taken':[]}\n",
    "            for _keyvalue_ in _response_lu_:\n",
    "                _file_save_info_['file'].append(_keyvalue_)\n",
    "                _file_save_info_['phi4_response'].append(_response_lu_[_keyvalue_])\n",
    "                _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "            df_intermediate = pd.DataFrame(_file_save_info_)\n",
    "            df_intermediate.to_parquet('INTERMEDIA_phi4_responses.parquet')\n",
    "        files_processed += 1\n",
    "    _file_save_info_ = {'file':[], 'phi4_response':[], 'time_taken':[]}\n",
    "    for _keyvalue_ in _response_lu_:\n",
    "        _file_save_info_['file'].append(_keyvalue_)\n",
    "        _file_save_info_['phi4_response'].append(_response_lu_[_keyvalue_])\n",
    "        _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "    df_final = pd.DataFrame(_file_save_info_)\n",
    "    df_final.to_parquet(_file_phi4_responses_)\n",
    "df_phi4          = pd.read_parquet(_file_phi4_responses_)\n",
    "df_phi4          = df_phi4.rename({'phi4_response':'model_response'}, axis=1)\n",
    "df_phi4['model'] = 'phi4:14b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_response_lu_, _timing_lu_ = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # model won't pull for some reason / error on local port when downloading\n",
    "_model_ = 'command-r7b'\n",
    "promptModel('what is 2+5?', _model_) # force an inference to load the model -- so that doesn't impact the timing\n",
    "\n",
    "_file_commandr7b_responses_ = _dir_ + '20250201_commandr7b_responses.parquet'\n",
    "if os.path.exists(_file_commandr7b_responses_) == False:    \n",
    "    total_files     = df['file'].nunique()\n",
    "    files_processed = 0\n",
    "    for k, k_df in df.groupby('file'):\n",
    "        if k in _response_lu_:\n",
    "            files_processed += 1 \n",
    "            continue\n",
    "        k_df             = k_df.sort_values('sentence_no').reset_index()\n",
    "        _article_        = ''.join(k_df['sentence'])\n",
    "        t0               = time.time()\n",
    "        _response_       = promptModel(f'Extract all of the entities into a Python dictionary from the following article.  The dictionary pairing should indicate the entities type:\\n\\n{_article_}', _model_)\n",
    "        _timing_lu_[k]   = time.time() - t0\n",
    "        _response_lu_[k] = _response_\n",
    "        print('.', end='')\n",
    "        if files_processed % 10 == 0:\n",
    "            print(f'{files_processed}/{total_files}', end='')\n",
    "            _file_save_info_ = {'file':[], 'commandr7b_response':[], 'time_taken':[]}\n",
    "            for _keyvalue_ in _response_lu_:\n",
    "                _file_save_info_['file'].append(_keyvalue_)\n",
    "                _file_save_info_['commandr7b_response'].append(_response_lu_[_keyvalue_])\n",
    "                _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "            df_intermediate = pd.DataFrame(_file_save_info_)\n",
    "            df_intermediate.to_parquet('INTERMEDIA_commandr7b_responses.parquet')\n",
    "        files_processed += 1\n",
    "    _file_save_info_ = {'file':[], 'commandr7b_response':[], 'time_taken':[]}\n",
    "    for _keyvalue_ in _response_lu_:\n",
    "        _file_save_info_['file'].append(_keyvalue_)\n",
    "        _file_save_info_['commandr7b_response'].append(_response_lu_[_keyvalue_])\n",
    "        _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "    df_final = pd.DataFrame(_file_save_info_)\n",
    "    df_final.to_parquet(_file_commandr7b_responses_)\n",
    "df_commandr7b          = pd.read_parquet(_file_commandr7b_responses_)\n",
    "df_commandr7b          = df_commandr7b.rename({'commandr7b_response':'model_response'}, axis=1)\n",
    "df_commandr7b['model'] = 'command-r7b'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_response_lu_, _timing_lu_ = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_ = 'granite3.1-dense'\n",
    "promptModel('what is 2+5?', _model_) # force an inference to load the model -- so that doesn't impact the timing\n",
    "\n",
    "_file_granite31dense_responses_ = _dir_ + '20250201_granite31dense_responses.parquet'\n",
    "if os.path.exists(_file_granite31dense_responses_) == False:\n",
    "    total_files     = df['file'].nunique()\n",
    "    files_processed = 0\n",
    "    for k, k_df in df.groupby('file'):\n",
    "        if k in _response_lu_:\n",
    "            files_processed += 1 \n",
    "            continue\n",
    "        k_df             = k_df.sort_values('sentence_no').reset_index()\n",
    "        _article_        = ''.join(k_df['sentence'])\n",
    "        t0               = time.time()\n",
    "        _response_       = promptModel(f'Extract all of the entities into a Python dictionary from the following article.  The dictionary pairing should indicate the entities type:\\n\\n{_article_}', _model_)\n",
    "        _timing_lu_[k]   = time.time() - t0\n",
    "        _response_lu_[k] = _response_\n",
    "        print('.', end='')\n",
    "        if files_processed % 10 == 0:\n",
    "            print(f'{files_processed}/{total_files}', end='')\n",
    "            _file_save_info_ = {'file':[], 'granite31dense_response':[], 'time_taken':[]}\n",
    "            for _keyvalue_ in _response_lu_:\n",
    "                _file_save_info_['file'].append(_keyvalue_)\n",
    "                _file_save_info_['granite31dense_response'].append(_response_lu_[_keyvalue_])\n",
    "                _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "            df_intermediate = pd.DataFrame(_file_save_info_)\n",
    "            df_intermediate.to_parquet('INTERMEDIA_granite31dense_responses.parquet')\n",
    "        files_processed += 1\n",
    "    _file_save_info_ = {'file':[], 'granite31dense_response':[], 'time_taken':[]}\n",
    "    for _keyvalue_ in _response_lu_:\n",
    "        _file_save_info_['file'].append(_keyvalue_)\n",
    "        _file_save_info_['granite31dense_response'].append(_response_lu_[_keyvalue_])\n",
    "        _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "    df_final = pd.DataFrame(_file_save_info_)\n",
    "    df_final.to_parquet(_file_granite31dense_responses_)\n",
    "df_granite31dense          = pd.read_parquet(_file_granite31dense_responses_)\n",
    "df_granite31dense          = df_granite31dense.rename({'granite31dense_response':'model_response'}, axis=1)\n",
    "df_granite31dense['model'] = 'granite31dense:8b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_response_lu_, _timing_lu_ = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_ = 'qwen2.5:14b'\n",
    "promptModel('what is 2+5?', _model_) # force an inference to load the model -- so that doesn't impact the timing\n",
    "\n",
    "_file_qwen25_responses_ = _dir_ + '20250201_qwen25_responses.parquet'\n",
    "if os.path.exists(_file_qwen25_responses_) == False:\n",
    "    total_files     = df['file'].nunique()\n",
    "    files_processed = 0\n",
    "    for k, k_df in df.groupby('file'):\n",
    "        if k in _response_lu_:\n",
    "            files_processed += 1 \n",
    "            continue\n",
    "        k_df             = k_df.sort_values('sentence_no').reset_index()\n",
    "        _article_        = ''.join(k_df['sentence'])\n",
    "        t0               = time.time()\n",
    "        _response_       = promptModel(f'Extract all of the entities into a Python dictionary from the following article.  The dictionary pairing should indicate the entities type:\\n\\n{_article_}', _model_)\n",
    "        _timing_lu_[k]   = time.time() - t0\n",
    "        _response_lu_[k] = _response_\n",
    "        print('.', end='')\n",
    "        if files_processed % 10 == 0:\n",
    "            print(f'{files_processed}/{total_files}', end='')\n",
    "            _file_save_info_ = {'file':[], 'qwen25_response':[], 'time_taken':[]}\n",
    "            for _keyvalue_ in _response_lu_:\n",
    "                _file_save_info_['file'].append(_keyvalue_)\n",
    "                _file_save_info_['qwen25_response'].append(_response_lu_[_keyvalue_])\n",
    "                _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "            df_intermediate = pd.DataFrame(_file_save_info_)\n",
    "            df_intermediate.to_parquet('INTERMEDIA_qwen25_responses.parquet')\n",
    "        files_processed += 1\n",
    "    _file_save_info_ = {'file':[], 'qwen25_response':[], 'time_taken':[]}\n",
    "    for _keyvalue_ in _response_lu_:\n",
    "        _file_save_info_['file'].append(_keyvalue_)\n",
    "        _file_save_info_['qwen25_response'].append(_response_lu_[_keyvalue_])\n",
    "        _file_save_info_['time_taken'].append(_timing_lu_[_keyvalue_])\n",
    "    df_final = pd.DataFrame(_file_save_info_)\n",
    "    df_final.to_parquet(_file_qwen25_responses_)\n",
    "df_qwen25          = pd.read_parquet(_file_qwen25_responses_)\n",
    "df_qwen25          = df_qwen25.rename({'qwen25_response':'model_response'}, axis=1)\n",
    "df_qwen25['model'] = 'qwen25:14b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df_responses                        = pd.concat([df_deepseek, df_llama32, df_phi4, df_qwen25, df_granite31dense])\n",
    "df_responses['model_response_len']  = df_responses['model_response'].str.len()\n",
    "df_responses['python']              = df_responses['model_response'].apply(lambda x: extractPythonBlock(x))\n",
    "df_responses['python_exists']       = df_responses['python'].apply(lambda x: x is not None)\n",
    "\n",
    "def extractDictionaryBlocks(_str_):\n",
    "    _dicts_ = []\n",
    "    _str_ = _str_.strip()\n",
    "    while (_str_.startswith('{') and '\\n}' in _str_) or ('\\n{' in _str_ and '\\n}' in _str_[_str_.index('\\n{'):]):\n",
    "        i0 = 0 if _str_.startswith('{') else _str_.index('\\n{')\n",
    "        i1 = _str_.index('\\n}',i0)\n",
    "        _dicts_.append(_str_[i0:i1+2])\n",
    "        _str_ = _str_[i1+1:]\n",
    "    return _dicts_\n",
    "\n",
    "entity_to_types_lu = {'entity':[], 'type':[], 'file':[], 'model':[]}\n",
    "def addEntityTyping(_dict_, _file_, _model_):\n",
    "    for k, v in _dict_.items():\n",
    "        if type(v) is list:\n",
    "            for _entity_ in v:\n",
    "                entity_to_types_lu['entity'].append(str(_entity_))\n",
    "                entity_to_types_lu['type']  .append(str(k))\n",
    "                entity_to_types_lu['file']  .append(_file_)\n",
    "                entity_to_types_lu['model'] .append(_model_)\n",
    "        elif type(v) is dict:\n",
    "            print(f'DICT {k=} {v=}')\n",
    "        elif type(v) is str:\n",
    "            entity_to_types_lu['entity'].append(str(k))\n",
    "            entity_to_types_lu['type']  .append(str(v))\n",
    "            entity_to_types_lu['file']  .append(_file_)\n",
    "            entity_to_types_lu['model'] .append(_model_)\n",
    "        else:\n",
    "            print(f'UNKN {k=} {v=}')\n",
    "\n",
    "_status_ = []\n",
    "for i in range(len(df_responses)):\n",
    "    _file_  = df_responses.iloc[i]['file']\n",
    "    _model_ = df_responses.iloc[i]['model']\n",
    "    if df_responses.iloc[i]['python'] is None: # NOT A PYTHON BLOCK ... BUT MAYBE SOMETHING THAT CAN BE EVALUATED\n",
    "        _dicts_maybe_ = extractDictionaryBlocks(df_responses.iloc[i]['model_response'])\n",
    "        if len(_dicts_maybe_) > 0:\n",
    "            _all_parsed_ = True\n",
    "            for _possible_ in _dicts_maybe_:\n",
    "                try:\n",
    "                    _dict_ = ast.literal_eval(_possible_)\n",
    "                    addEntityTyping(_dict_, _file_, _model_)\n",
    "                except:\n",
    "                    _all_parsed_ = False\n",
    "            if _all_parsed_:  _status_.append('Evaled - Non-Python Block')\n",
    "            else:             _status_.append('Exception - Non-Python Block')\n",
    "        else: _status_.append('None')\n",
    "    else: # A PYTHON BLOCK ... BUT CAN IT BE SAFELY EVALED?\n",
    "        _str_ = df_responses.iloc[i]['python'].strip()\n",
    "        if 'entities ='      in _str_: _str_ = _str_.replace('entities =', '')\n",
    "        if 'print(entities)' in _str_: _str_ = _str_.replace('print(entities)', '')\n",
    "        _article_str_ = 'article_'\n",
    "        if _str_.startswith(_article_str_): _str_ = _str_[len(_article_str_):]\n",
    "        _str_ = _str_.strip()\n",
    "        try:\n",
    "            _dictionary_ = ast.literal_eval(_str_)\n",
    "            if type(_dictionary_) is list: \n",
    "                _status_.append('Evaled-List')\n",
    "                for x in _dictionary_:\n",
    "                    if type(x) is dict: addEntityTyping(x, _file_, _model_)\n",
    "                    else:\n",
    "                        print('---') \n",
    "                        print(x)\n",
    "            if type(_dictionary_) == dict: \n",
    "                _status_.append('Evaled')\n",
    "                addEntityTyping(_dictionary_, _file_, _model_)\n",
    "        except:\n",
    "            _status_.append('Exception')\n",
    "            last_failed_str  = _str_\n",
    "            last_failed_orig = df_responses.iloc[i]['python']\n",
    "df_responses['python_status'] = _status_\n",
    "_h_ = 128\n",
    "rt.tile([rt.histogram(df_responses, bin_by='model', count_by='time_taken',         color_by='model',         w=256, h=_h_),\n",
    "         rt.histogram(df_responses, bin_by='model', count_by='model_response_len', color_by='model',         w=256, h=_h_),\n",
    "         rt.histogram(df_responses, bin_by='model',                                color_by='python_exists', w=256, h=_h_),\n",
    "         rt.histogram(df_responses, bin_by='model',                                color_by='python_status', w=256, h=_h_),\n",
    "         rt.histogram(df_responses, bin_by='python_status',                        color_by='python_status', w=256, h=_h_)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created this by hand\n",
    "aggregate_type_to_entity_type = {'organization':   ['organizations', 'company', 'companies', 'company/organization', 'org', 'orgs',\n",
    "                                                    'group', 'groups', 'group/organization', 'organization/group'],\n",
    "                                 'government':     ['government', 'governments', 'country', 'countries', 'nation', 'nations', 'government entity'],\n",
    "                                 'person':         ['person', 'people', 'persons'],\n",
    "                                 'event':          ['event', 'events'],\n",
    "                                 'location':       ['location', 'locations', 'place', 'places', 'facility', 'facilities'],\n",
    "                                 'date':           ['date', 'dates'],\n",
    "                                 'time':           ['time', 'times', 'date/time'],\n",
    "                                 'action':         ['action', 'actions'],\n",
    "                                 'object':         ['object', 'objects'],\n",
    "                                 'entity':         ['entity', 'entities'],\n",
    "                                 'topic':          ['topics', 'topic', 'issue', 'issues'],\n",
    "                                 'chemical/drugs': ['chemical', 'chemicals', 'drug', 'drugs', 'substance', 'substances'],\n",
    "                                 'other':          ['other', 'others', 'miscellaneous']}\n",
    "_lu_ = {}\n",
    "for k, v in aggregate_type_to_entity_type.items():\n",
    "    for _entity_ in v:\n",
    "        _lu_[_entity_] = k\n",
    "df_entity_types = pd.DataFrame(entity_to_types_lu)\n",
    "df_entity_types['type_agg'] = df_entity_types['type'].apply(lambda x: _lu_[x.lower()] if x.lower() in _lu_ else x.lower())\n",
    "_w_, _h_ = 256, 256\n",
    "rt.tile([rt.histogram(df_entity_types, bin_by='model',     color_by='type',     w=_w_, h=_h_),\n",
    "         rt.histogram(df_entity_types, bin_by='type',      color_by='type',     w=_w_, h=_h_),\n",
    "         rt.histogram(df_entity_types, bin_by='model',     color_by='type_agg', w=_w_, h=_h_),\n",
    "         rt.histogram(df_entity_types, bin_by='type_agg',  color_by='type_agg', w=_w_, h=_h_)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No variations of this worked / with any of the models...  they'd return plain language descriptions ... but i don't believe any of them were complete\n",
    "#_model_    = 'deepseek-r1:14b'\n",
    "#_prompt_   = f'Create a Python function that coverts all of the following entity types into aggregate types. {df_entity_types[\"type\"].unique().tolist()}'\n",
    "#_response_ = promptModel(_prompt_, _model_)\n",
    "#print(_response_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import networkx as nx\n",
    "#relates = [('entity','type')]\n",
    "#g       = rt.createNetworkXGraph(df_entity_types, relates)\n",
    "#pos     = nx.spring_layout(g) # about 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = rt.layoutSimpleTemplates(g, pos)\n",
    "#igl     = rt.interactiveGraphLayout(df_entity_types, ln_params={'relationships':relates, 'pos':pos, 'node_size':'small'}, w=2200, h=900)\n",
    "#igl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_    = '5.txt'\n",
    "_article_ = ' '.join(df_articles.query('file == @_file_').sort_values('sentence_no')['sentence'])\n",
    "_df_ents_ = df_entity_types.query('file == @_file_').reset_index()\n",
    "my_markup = {}\n",
    "for i in range(len(_df_ents_)):\n",
    "    _model_  = _df_ents_.iloc[i]['model']\n",
    "    _entity_ = _df_ents_.iloc[i]['entity']\n",
    "    if _model_ not in my_markup: my_markup[_model_] = {}\n",
    "    my_markup[_model_][_entity_] = rt.co_mgr.getColor(_model_)\n",
    "_txt_blk_ = rt.textBlock(_article_, word_wrap=True, w=384)\n",
    "_tiles_   = []\n",
    "_svg_lu_  = _txt_blk_.highlightsComparison(my_markup)\n",
    "_tiles_.append(_svg_lu_['__all__'])\n",
    "for x in _svg_lu_:\n",
    "    if x == '__all__': continue\n",
    "    _tiles_.append(_svg_lu_[x])\n",
    "_tiles_.append(rt.histogram(_df_ents_, bin_by='model', color_by='model', w=160, h=256))\n",
    "rt.tile(_tiles_, spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_ents_.query('model == \"deepseek-r1:14b\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
