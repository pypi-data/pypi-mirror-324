[model]
dim = 5120
n_vocab = 102400
hf_model_id = "deepseek-ai/DeepSeek-V2"
pad_token = "<｜end▁of▁sentence｜>"

[tokenizer]
return_tensors = "pt"
return_attention_mask = true
max_length = 256
padding = "longest"
truncation = true
add_special_tokens = false

[training]
output_dir = "output/matryoshka_deepseekv2"
num_train_epochs = 2
per_device_train_batch_size = 256
warmup_steps = 256
evaluation_strategy = "steps"
eval_steps = 500
save_steps = 4000
fp16 = true
include_num_input_tokens_seen = false
learning_rate = 3e-4
multi_dataset_batch_sampler = "PROPORTIONAL"
binarizer_ste = "ste"

[matryoshka]
dims = [1024, 512, 256, 128, 64]

