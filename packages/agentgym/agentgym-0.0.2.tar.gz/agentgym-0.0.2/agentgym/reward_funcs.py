# Load and prep dataset

import re
from typing import List, Optional
from datasets import load_dataset, Dataset

SYSTEM_PROMPT = """
Respond in the following format:

<reasoning>
...
</reasoning>
<answer>
...
</answer>
"""

XML_COT_FORMAT = """\
<reasoning>
{reasoning}
</reasoning>
<answer>
{answer}
</answer>
"""


def extract_xml_answer(text: str) -> str:
    """
    Extracts the answer from a given text formatted in XML.

    Args:
    - text (str): The text from which to extract the answer.

    Returns:
    - str: The extracted answer.
    """
    answer = text.split("<answer>")[-1]
    answer = answer.split("</answer>")[0]
    return answer.strip()


def extract_hash_answer(text: str) -> Optional[str]:
    """
    Extracts the answer from a given text formatted with a hash.

    Args:
    - text (str): The text from which to extract the answer.

    Returns:
    - Optional[str]: The extracted answer if found, otherwise None.
    """
    if "####" not in text:
        return None
    return text.split("####")[1].strip()


# uncomment middle messages for 1-shot prompting
def get_gsm8k_questions(split: str = "train") -> Dataset:
    """
    Loads and prepares the GSM8K dataset for a given split.

    Args:
    - split (str): The split of the dataset to load. Defaults to "train".

    Returns:
    - Dataset: The prepared dataset.
    """
    data = load_dataset("openai/gsm8k", "main")[split]  # type: ignore
    data = data.map(
        lambda x: {  # type: ignore
            "prompt": [
                {"role": "system", "content": SYSTEM_PROMPT},
                # {'role': 'user', 'content': 'What is the largest single-digit prime number?'},
                # {'role': 'assistant', 'content': XML_COT_FORMAT.format(
                #    reasoning="9 is divisble by 3 and 8 is divisible by 2, but 7 is prime.",
                #    answer="7"
                # )},
                {"role": "user", "content": x["question"]},
            ],
            "answer": extract_hash_answer(x["answer"]),
        }
    )  # type: ignore
    return data  # type: ignore


dataset = get_gsm8k_questions()


# Reward functions
def correctness_reward_func(
    prompts: List[dict],
    completions: List[dict],
    answer: List[str],
    **kwargs,
) -> List[float]:
    """
    Calculates the reward based on the correctness of the completion.

    Args:
    - prompts (List[dict]): The prompts given to the model.
    - completions (List[dict]): The completions generated by the model.
    - answer (List[str]): The correct answers.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion.
    """
    responses = [
        completion[0]["content"] for completion in completions
    ]
    q = prompts[0][-1]["content"]
    extracted_responses = [extract_xml_answer(r) for r in responses]
    print(
        "-" * 20,
        f"Question:\n{q}",
        f"\nAnswer:\n{answer[0]}",
        f"\nResponse:\n{responses[0]}",
        f"\nExtracted:\n{extracted_responses[0]}",
    )
    return [
        2.0 if r == a else 0.0
        for r, a in zip(extracted_responses, answer)
    ]


def int_reward_func(completions: List[dict], **kwargs) -> List[float]:
    """
    Calculates the reward based on whether the completion is an integer.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion.
    """
    responses = [
        completion[0]["content"] for completion in completions
    ]
    extracted_responses = [extract_xml_answer(r) for r in responses]
    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]


def strict_format_reward_func(
    completions: List[dict], **kwargs
) -> List[float]:
    """
    Calculates the reward based on whether the completion follows a strict format.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion.
    """
    pattern = r"^<reasoning>\n.*?\n</reasoning>\n<answer>\n.*?\n</answer>\n$"
    responses = [
        completion[0]["content"] for completion in completions
    ]
    matches = [re.match(pattern, r) for r in responses]
    return [0.5 if match else 0.0 for match in matches]


def soft_format_reward_func(
    completions: List[dict], **kwargs
) -> List[float]:
    """
    Calculates the reward based on whether the completion follows a soft format.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion.
    """
    pattern = r"<reasoning>.*?</reasoning>\s*<answer>.*?</answer>"
    responses = [
        completion[0]["content"] for completion in completions
    ]
    matches = [re.match(pattern, r) for r in responses]
    return [0.5 if match else 0.0 for match in matches]


def count_xml(text: str) -> float:
    """
    Counts the occurrences of specific XML tags in a given text.

    Args:
    - text (str): The text to count XML tags in.

    Returns:
    - float: A score based on the count of XML tags.
    """
    count = 0.0
    if text.count("<reasoning>\n") == 1:
        count += 0.125
    if text.count("\n</reasoning>\n") == 1:
        count += 0.125
    if text.count("\n<answer>\n") == 1:
        count += 0.125
        count -= len(text.split("\n</answer>\n")[-1]) * 0.001
    if text.count("\n</answer>") == 1:
        count += 0.125
        count -= (len(text.split("\n</answer>")[-1]) - 1) * 0.001
    return count


def xmlcount_reward_func(
    completions: List[dict], **kwargs
) -> List[float]:
    """
    Calculates the reward based on the count of XML tags in the completion.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion.
    """
    contents = [
        completion[0]["content"] for completion in completions
    ]
    return [count_xml(c) for c in contents]


def reward_len(completions: List[dict], **kwargs) -> List[float]:
    """
    Calculates the reward based on the length of the completion, rewarding those close to 20 characters.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion, where the reward is the absolute difference between the length of the completion and 20.
    """
    return [abs(20 - len(completion)) for completion in completions]


def reward_len_strict(
    completions: List[dict], **kwargs
) -> List[float]:
    """
    Calculates the reward based on the length of the completion, rewarding those close to 20 characters.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion, where the reward is the absolute difference between the length of the completion and 20.
    """
    return [abs(20 - len(completion)) for completion in completions]


def reward_func(completions: List[dict], **kwargs) -> List[float]:
    """
    Reward function that gives higher scores to longer completions.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion, where the reward is the length of the completion.
    """
    return [float(len(completion)) for completion in completions]


def format_reward_func(
    completions: List[dict], **kwargs
) -> List[float]:
    """
    Reward function that checks if the completion has a specific format.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion, where the reward is 1.0 if the completion matches the specific format, 0.0 otherwise.
    """
    pattern = r"^<think>.*?</think><answer>.*?</answer>$"
    completion_contents = [
        completion[0]["content"] for completion in completions
    ]
    matches = [
        re.match(pattern, content) for content in completion_contents
    ]
    return [1.0 if match else 0.0 for match in matches]


def reward_func_for_format(
    completions: List[dict], ground_truth: List[str], **kwargs
) -> List[float]:
    """
    Reward function that rewards completions based on their content matching the ground truth.

    Args:
    - completions (List[dict]): The completions generated by the model.
    - ground_truth (List[str]): The expected correct answers.
    - **kwargs: Additional keyword arguments.

    Returns:
    - List[float]: A list of rewards for each completion, where the reward is 1.0 if the content matches the ground truth, 0.0 otherwise.
    """
    # Regular expression to capture content inside \boxed{}
    matches = [
        re.search(r"\\boxed\{(.*?)\}", completion)
        for completion in completions
    ]
    contents = [match.group(1) if match else "" for match in matches]
    # Reward 1 if the content is the same as the ground truth, 0 otherwise
    return [
        1.0 if c == gt else 0.0
        for c, gt in zip(contents, ground_truth)
    ]
